#!/usr/bin/env python3
"""
Ollama Chat Bot –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π FastAPI API –≤–º–µ—Å—Ç–æ CLI
–ë–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π API –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
"""

import os
import json
import asyncio
import aiohttp
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
import signal

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/ollama_api_bot.log', encoding='utf-8')
    ]
)

@dataclass
class ChatMessage:
    role: str  # "user", "assistant", "system"
    content: str
    timestamp: str
    model_used: str = "unknown"
    tokens_used: Optional[int] = None

@dataclass
class ChatSession:
    session_id: str
    chat_id: int
    user_id: int
    user_name: str
    started_at: str
    last_activity: str
    messages: List[ChatMessage]
    preferred_model: str = "ollama"
    total_tokens: int = 0

class APIClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å FastAPI —Å–µ—Ä–≤–µ—Ä–æ–º"""
    
    def __init__(self, api_base_url: str = "http://localhost:8000"):
        self.api_base_url = api_base_url
        self.session = None
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def health_check(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API"""
        async with self.session.get(f"{self.api_base_url}/api/v1/system/health") as response:
            return await response.json()
    
    async def system_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã"""
        async with self.session.get(f"{self.api_base_url}/api/v1/system/status") as response:
            return await response.json()
    
    async def chat_message(self, message: str, context_mode: str = "focused", session_id: str = "default") -> Dict[str, Any]:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —á–∞—Ç —á–µ—Ä–µ–∑ API"""
        payload = {
            "message": message,
            "context_mode": context_mode,
            "session_id": session_id
        }
        async with self.session.post(f"{self.api_base_url}/api/v1/chat/message", json=payload) as response:
            return await response.json()
    
    async def execute_cli_command(self, command: str, args: Dict[str, Any] = None) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ CLI –∫–æ–º–∞–Ω–¥—ã —á–µ—Ä–µ–∑ API"""
        payload = {
            "command": command,
            "args": args or {}
        }
        async with self.session.post(f"{self.api_base_url}/api/v1/cli/execute", json=payload) as response:
            return await response.json()
    
    async def get_metrics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫"""
        async with self.session.get(f"{self.api_base_url}/api/v1/metrics") as response:
            return await response.json()

class ModelManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä LLM –º–æ–¥–µ–ª–µ–π —Å API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π"""
    
    def __init__(self, api_client: APIClient):
        self.api_client = api_client
        self.ollama_url = "http://localhost:11434"
        
    async def chat_with_ollama(self, messages: List[Dict], model: str = "llama3.2") -> Optional[str]:
        """–û–±—â–µ–Ω–∏–µ —Å Ollama —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–π API"""
        try:
            async with aiohttp.ClientSession() as session:
                payload = {
                    "model": model,
                    "messages": messages,
                    "stream": False
                }
                async with session.post(f"{self.ollama_url}/api/chat", json=payload) as response:
                    if response.status == 200:
                        result = await response.json()
                        return result["message"]["content"]
                    else:
                        logging.error(f"Ollama API error: {response.status}")
                        return None
        except Exception as e:
            logging.error(f"Ollama connection error: {e}")
            return None
    
    async def chat_with_api_fallback(self, message: str, session_id: str) -> str:
        """Fallback —á–µ—Ä–µ–∑ FastAPI —á–∞—Ç"""
        try:
            result = await self.api_client.chat_message(message, "focused", session_id)
            return result.get("response", "API fallback response not available")
        except Exception as e:
            logging.error(f"API fallback error: {e}")
            return "‚ö†Ô∏è –ò–∑–≤–∏–Ω–∏—Ç–µ, –≤—Å–µ —Å–∏—Å—Ç–µ–º—ã –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"

class FileManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ API"""
    
    def __init__(self, api_client: APIClient):
        self.api_client = api_client
        self.project_root = "/home/sma/projects/llmstruct/llmstruct"
    
    async def read_file(self, file_path: str, max_lines: int = 100) -> str:
        """–ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ API –∫–æ–º–∞–Ω–¥—ã"""
        try:
            # –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CLI —á–µ—Ä–µ–∑ API
            args = {"path": file_path, "lines": max_lines}
            result = await self.api_client.execute_cli_command("query", args)
            return result.get("stdout", "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}"
    
    async def get_system_status(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã"""
        try:
            status = await self.api_client.system_status()
            return f"""üìä **–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã LLMStruct**

üü¢ **API**: {status['system']['status']}
üìÅ **struct.json**: {status['struct_json']['status']} ({status['struct_json']['size_bytes']} –±–∞–π—Ç)
üìä **–ú–µ—Ç—Ä–∏–∫–∏**: {'–≤–∫–ª—é—á–µ–Ω—ã' if status['features']['metrics'] else '–æ—Ç–∫–ª—é—á–µ–Ω—ã'}
üîß **–§—É–Ω–∫—Ü–∏–∏**: {', '.join([k for k, v in status['features'].items() if v])}

‚è∞ –û–±–Ω–æ–≤–ª–µ–Ω–æ: {status['system']['timestamp']}"""
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}"

class MemoryManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏ —Å API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π"""
    
    def __init__(self, storage_dir: str = "data/ollama_api_chat", api_client: APIClient = None):
        self.storage_dir = storage_dir
        self.api_client = api_client
        self.sessions_file = f"{storage_dir}/sessions.json"
        self.sessions: Dict[str, ChatSession] = {}
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        os.makedirs(storage_dir, exist_ok=True)
        self._load_data()
    
    def _load_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–µ—Å—Å–∏–π –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            if os.path.exists(self.sessions_file):
                with open(self.sessions_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for session_data in data.get('sessions', []):
                        session = ChatSession(**session_data)
                        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π
                        session.messages = [ChatMessage(**msg) for msg in session.messages]
                        self.sessions[session.session_id] = session
        except Exception as e:
            logging.error(f"Error loading sessions: {e}")
    
    def _save_data(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ—Å—Å–∏–π –≤ —Ñ–∞–π–ª"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ JSON-serializable —Ñ–æ—Ä–º–∞—Ç
            sessions_data = []
            for session in self.sessions.values():
                session_dict = asdict(session)
                sessions_data.append(session_dict)
            
            data = {
                "sessions": sessions_data,
                "last_saved": datetime.now().isoformat()
            }
            
            with open(self.sessions_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logging.error(f"Error saving sessions: {e}")
    
    def get_or_create_session(self, chat_id: int, user_id: int, user_name: str) -> ChatSession:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏"""
        session_id = f"chat_{chat_id}_{user_id}"
        
        if session_id not in self.sessions:
            self.sessions[session_id] = ChatSession(
                session_id=session_id,
                chat_id=chat_id,
                user_id=user_id,
                user_name=user_name,
                started_at=datetime.now().isoformat(),
                last_activity=datetime.now().isoformat(),
                messages=[],
                preferred_model="ollama",
                total_tokens=0
            )
        
        return self.sessions[session_id]
    
    def add_message(self, session: ChatSession, role: str, content: str, model_used: str = "unknown"):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Å–µ—Å—Å–∏—é"""
        message = ChatMessage(
            role=role,
            content=content,
            timestamp=datetime.now().isoformat(),
            model_used=model_used
        )
        
        session.messages.append(message)
        session.last_activity = datetime.now().isoformat()
        session.total_tokens += len(content.split())  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏
        if len(session.messages) > 100:
            session.messages = session.messages[-50:]
        
        self._save_data()

class OllamaAPIBot:
    """Telegram –±–æ—Ç —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π FastAPI"""
    
    def __init__(self, bot_token: str, api_base_url: str = "http://localhost:8000"):
        self.bot_token = bot_token
        self.bot_url = f"https://api.telegram.org/bot{bot_token}"
        self.api_base_url = api_base_url
        self.api_client = None
        self.running = False
        
        # –ú–µ–Ω–µ–¥–∂–µ—Ä—ã
        self.memory = MemoryManager()
        self.logger = logging.getLogger(__name__)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
        signal.signal(signal.SIGTERM, self._signal_handler)
        signal.signal(signal.SIGINT, self._signal_handler)
    
    def _signal_handler(self, signum, frame):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è graceful shutdown"""
        self.logger.info(f"üõë Received signal {signum}, shutting down...")
        self.running = False
    
    async def send_message(self, chat_id: int, text: str, parse_mode: str = "Markdown"):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram"""
        try:
            async with aiohttp.ClientSession() as session:
                payload = {
                    "chat_id": chat_id,
                    "text": text,
                    "parse_mode": parse_mode
                }
                async with session.post(f"{self.bot_url}/sendMessage", json=payload) as response:
                    return await response.json()
        except Exception as e:
            self.logger.error(f"Failed to send message: {e}")
            return None
    
    async def get_updates(self, offset: int = 0):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –æ—Ç Telegram"""
        try:
            async with aiohttp.ClientSession() as session:
                params = {"offset": offset, "timeout": 10}
                async with session.get(f"{self.bot_url}/getUpdates", params=params) as response:
                    return await response.json()
        except Exception as e:
            self.logger.error(f"Failed to get updates: {e}")
            return None
    
    async def chat_with_ai(self, session: ChatSession, user_message: str) -> str:
        """–û–±—â–µ–Ω–∏–µ —Å AI —á–µ—Ä–µ–∑ —Ä–∞–∑–ª–∏—á–Ω—ã–µ API"""
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        messages = []
        for msg in session.messages[-10:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
            messages.append({
                "role": msg.role,
                "content": msg.content
            })
        
        messages.append({
            "role": "user", 
            "content": user_message
        })
        
        # –ü—Ä–æ–±—É–µ–º Ollama
        model_manager = ModelManager(self.api_client)
        response = await model_manager.chat_with_ollama(messages)
        
        if response:
            return response
        
        # Fallback —á–µ—Ä–µ–∑ FastAPI
        return await model_manager.chat_with_api_fallback(user_message, session.session_id)
    
    async def handle_message(self, update):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        try:
            message = update.get("message")
            if not message:
                return
            
            chat_id = message["chat"]["id"]
            user_id = message["from"]["id"]
            user_name = message["from"].get("first_name", "User")
            text = message.get("text", "")
            
            if not text:
                return
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏
            session = self.memory.get_or_create_session(chat_id, user_id, user_name)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥
            if text.startswith("/"):
                await self.handle_command(chat_id, text, session)
                return
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            self.memory.add_message(session, "user", text)
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç AI
            ai_response = await self.chat_with_ai(session, text)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ AI
            self.memory.add_message(session, "assistant", ai_response, "ollama_api")
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞
            await self.send_message(chat_id, ai_response)
            
        except Exception as e:
            self.logger.error(f"Error handling message: {e}")
            if "chat_id" in locals():
                await self.send_message(chat_id, "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è")
    
    async def handle_command(self, chat_id: int, command: str, session: ChatSession):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥ –±–æ—Ç–∞"""
        
        if command == "/start":
            response = f"""ü§ñ **Ollama API Bot**

–ü—Ä–∏–≤–µ—Ç, {session.user_name}! –Ø –±–æ—Ç —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π FastAPI.

**–ö–æ–º–∞–Ω–¥—ã:**
/status - —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã —á–µ—Ä–µ–∑ API
/metrics - –º–µ—Ç—Ä–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã  
/health - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API
/help - —ç—Ç–∞ —Å–ø—Ä–∞–≤–∫–∞

–ü—Ä–æ—Å—Ç–æ –ø–∏—à–∏—Ç–µ –º–Ω–µ, –∏ —è –æ—Ç–≤–µ—á—É —á–µ—Ä–µ–∑ Ollama –∏–ª–∏ API fallback!"""
            
        elif command == "/status":
            file_manager = FileManager(self.api_client)
            response = await file_manager.get_system_status()
            
        elif command == "/metrics":
            try:
                metrics = await self.api_client.get_metrics()
                response = f"""üìä **–ú–µ—Ç—Ä–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã**

**–°–µ—Å—Å–∏—è**: {metrics['session_summary'].get('session_id', 'N/A')}
**–¢–æ–∫–µ–Ω—ã**: {metrics['session_summary'].get('total_tokens', 0)}
**–°–æ–±—ã—Ç–∏—è**: {len(metrics['session_summary'].get('events', []))}

üí¨ **–ß–∞—Ç**: {len(session.messages)} —Å–æ–æ–±—â–µ–Ω–∏–π, {session.total_tokens} —Ç–æ–∫–µ–Ω–æ–≤"""
            except Exception as e:
                response = f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {e}"
        
        elif command == "/health":
            try:
                health = await self.api_client.health_check()
                status_emoji = "üü¢" if health["status"] == "healthy" else "üî¥"
                response = f"""{status_emoji} **API Health Check**

**–°—Ç–∞—Ç—É—Å**: {health['status']}
**–í–µ—Ä—Å–∏—è**: {health['api_version']}
**–ú–µ—Ç—Ä–∏–∫–∏**: {'–≤–∫–ª—é—á–µ–Ω—ã' if health['metrics_enabled'] else '–æ—Ç–∫–ª—é—á–µ–Ω—ã'}
**–í—Ä–µ–º—è**: {health['timestamp']}"""
            except Exception as e:
                response = f"‚ùå API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}"
        
        elif command == "/help":
            response = """ü§ñ **Ollama API Bot - –°–ø—Ä–∞–≤–∫–∞**

**–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:**
/start - –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
/status - —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã LLMStruct
/metrics - –º–µ—Ç—Ä–∏–∫–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
/health - –ø—Ä–æ–≤–µ—Ä–∫–∞ API
/help - —ç—Ç–∞ —Å–ø—Ä–∞–≤–∫–∞

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å FastAPI
‚úÖ Ollama + API fallback
‚úÖ –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
‚úÖ –ü–∞–º—è—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤

–ü—Ä–æ—Å—Ç–æ –ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è - —è –æ—Ç–≤–µ—á—É!"""
        
        else:
            response = "‚ùì –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /help –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏."
        
        await self.send_message(chat_id, response)
        self.memory.add_message(session, "assistant", response, "command")
    
    async def run(self):
        """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
        self.running = True
        offset = 0
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API –∫–ª–∏–µ–Ω—Ç–∞
        self.api_client = APIClient(self.api_base_url)
        
        async with self.api_client:
            self.logger.info("üöÄ Ollama API Bot –∑–∞–ø—É—â–µ–Ω!")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ API
            try:
                health = await self.api_client.health_check()
                self.logger.info(f"‚úÖ API –¥–æ—Å—Ç—É–ø–µ–Ω: {health['status']}")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            
            while self.running:
                try:
                    updates = await self.get_updates(offset)
                    
                    if updates and updates.get("ok"):
                        for update in updates.get("result", []):
                            await self.handle_message(update)
                            offset = update["update_id"] + 1
                    
                    await asyncio.sleep(1)
                    
                except Exception as e:
                    self.logger.error(f"Error in main loop: {e}")
                    await asyncio.sleep(5)
        
        self.logger.info("‚úÖ Bot shutdown complete")

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    token = os.getenv("TELEGRAM_BOT_TOKEN")
    if not token:
        print("‚ùå TELEGRAM_BOT_TOKEN not set")
        return 1
    
    api_url = os.getenv("API_BASE_URL", "http://localhost:8000")
    
    bot = OllamaAPIBot(token, api_url)
    
    try:
        await bot.run()
    except KeyboardInterrupt:
        logging.info("üõë Bot stopped by user")
    except Exception as e:
        logging.error(f"‚ùå Fatal error: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(asyncio.run(main())) 