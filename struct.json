{
  "metadata": {
    "project_name": "llmstruct",
    "description": "Utility for generating structured JSON for codebases",
    "version": "2025-05-21T18:15:19.637195Z",
    "authors": [
      {
        "name": "Mikhail Stepanov",
        "github": "kpblcaoo",
        "email": "kpblcaoo@gmail.com"
      }
    ],
    "instructions": [
      "Follow best practices, warn if instructions conflict with them",
      "Preserve functionality, ensure idempotency",
      "Use attached struct.json for context and navigation",
      "Request missing modules or functions if needed",
      "Regenerate JSON for significant changes, track via Git and artifacts",
      "Use internal comments for descriptions, append brief summary"
    ],
    "goals": {
      "goals": [
        "Create universal JSON format for codebase structure (modules, functions, classes, calls, metadata)",
        "Ensure extensibility for new languages and entity types",
        "Develop modular, plugin-based parsers for new languages",
        "Maintain an open, RFC-style documented format",
        "Integrate with LLMs by generating and attaching JSON structure to queries"
      ]
    },
    "stats": {
      "modules_count": 19,
      "functions_count": 62,
      "classes_count": 5,
      "call_edges_count": 225
    },
    "folder_structure": [
      {
        "path": ".",
        "type": "directory"
      },
      {
        "path": ".github",
        "type": "directory"
      },
      {
        "path": ".github\\workflows",
        "type": "directory"
      },
      {
        "path": "collector.py",
        "type": "file"
      },
      {
        "path": "data",
        "type": "directory"
      },
      {
        "path": "data.old",
        "type": "directory"
      },
      {
        "path": "docs",
        "type": "directory"
      },
      {
        "path": "docs\\examples",
        "type": "directory"
      },
      {
        "path": "docs\\internal",
        "type": "directory"
      },
      {
        "path": "docs\\internal\\ru",
        "type": "directory"
      },
      {
        "path": "docs\\ru",
        "type": "directory"
      },
      {
        "path": "docs\\ru\\examples",
        "type": "directory"
      },
      {
        "path": "examples",
        "type": "directory"
      },
      {
        "path": "examples\\python_project_main.py",
        "type": "file"
      },
      {
        "path": "examples\\python_project_utils.py",
        "type": "file"
      },
      {
        "path": "scripts",
        "type": "directory"
      },
      {
        "path": "src",
        "type": "directory"
      },
      {
        "path": "src\\llmstruct",
        "type": "directory"
      },
      {
        "path": "src\\llmstruct.egg-info",
        "type": "directory"
      },
      {
        "path": "src\\llmstruct\\__init__.py",
        "type": "file"
      },
      {
        "path": "src\\llmstruct\\__main__.py",
        "type": "file"
      },
      {
        "path": "src\\llmstruct\\cli.py",
        "type": "file"
      },
      {
        "path": "src\\llmstruct\\generators",
        "type": "directory"
      },
      {
        "path": "src\\llmstruct\\generators\\__init__.py",
        "type": "file"
      },
      {
        "path": "src\\llmstruct\\generators\\json_generator.py",
        "type": "file"
      },
      {
        "path": "src\\llmstruct\\grok.py",
        "type": "file"
      },
      {
        "path": "src\\llmstruct\\llm_client.py",
        "type": "file"
      },
      {
        "path": "src\\llmstruct\\parsers",
        "type": "directory"
      },
      {
        "path": "src\\llmstruct\\parsers\\__init__.py",
        "type": "file"
      },
      {
        "path": "src\\llmstruct\\parsers\\javascript_parser.py",
        "type": "file"
      },
      {
        "path": "src\\llmstruct\\parsers\\python_parser.py",
        "type": "file"
      },
      {
        "path": "src\\llmstruct\\self_run.py",
        "type": "file"
      },
      {
        "path": "src\\llmstruct\\templates",
        "type": "directory"
      },
      {
        "path": "src\\llmstruct\\templates\\__init__.py",
        "type": "file"
      },
      {
        "path": "src\\llmstruct\\validators",
        "type": "directory"
      },
      {
        "path": "src\\llmstruct\\validators\\__init__.py",
        "type": "file"
      },
      {
        "path": "src\\llmstruct\\validators\\json_validator.py",
        "type": "file"
      },
      {
        "path": "test_efficiency.py",
        "type": "file"
      },
      {
        "path": "tests",
        "type": "directory"
      },
      {
        "path": "tmp",
        "type": "directory"
      },
      {
        "path": "verify_llm_response.py",
        "type": "file"
      }
    ]
  },
  "toc": [
    {
      "module_id": "collector",
      "path": "collector.py",
      "category": "core",
      "functions": 3,
      "classes": 0,
      "summary": ""
    },
    {
      "module_id": "test_efficiency",
      "path": "test_efficiency.py",
      "category": "test",
      "functions": 12,
      "classes": 0,
      "summary": ""
    },
    {
      "module_id": "verify_llm_response",
      "path": "verify_llm_response.py",
      "category": "core",
      "functions": 6,
      "classes": 0,
      "summary": ""
    },
    {
      "module_id": "examples.python_project_main",
      "path": "examples\\python_project_main.py",
      "category": "core",
      "functions": 2,
      "classes": 1,
      "summary": "Main module for the sample project."
    },
    {
      "module_id": "examples.python_project_utils",
      "path": "examples\\python_project_utils.py",
      "category": "core",
      "functions": 2,
      "classes": 0,
      "summary": "Utility functions for the sample project."
    },
    {
      "module_id": "src.llmstruct.cli",
      "path": "src\\llmstruct\\cli.py",
      "category": "core",
      "functions": 8,
      "classes": 0,
      "summary": ""
    },
    {
      "module_id": "src.llmstruct.grok",
      "path": "src\\llmstruct\\grok.py",
      "category": "core",
      "functions": 3,
      "classes": 1,
      "summary": ""
    },
    {
      "module_id": "src.llmstruct.llm_client",
      "path": "src\\llmstruct\\llm_client.py",
      "category": "core",
      "functions": 6,
      "classes": 1,
      "summary": ""
    },
    {
      "module_id": "src.llmstruct.self_run",
      "path": "src\\llmstruct\\self_run.py",
      "category": "core",
      "functions": 2,
      "classes": 0,
      "summary": ""
    },
    {
      "module_id": "src.llmstruct.__init__",
      "path": "src\\llmstruct\\__init__.py",
      "category": "cli",
      "functions": 0,
      "classes": 0,
      "summary": ""
    },
    {
      "module_id": "src.llmstruct.__main__",
      "path": "src\\llmstruct\\__main__.py",
      "category": "cli",
      "functions": 0,
      "classes": 0,
      "summary": ""
    },
    {
      "module_id": "src.llmstruct.generators.json_generator",
      "path": "src\\llmstruct\\generators\\json_generator.py",
      "category": "core",
      "functions": 3,
      "classes": 0,
      "summary": ""
    },
    {
      "module_id": "src.llmstruct.generators.__init__",
      "path": "src\\llmstruct\\generators\\__init__.py",
      "category": "cli",
      "functions": 0,
      "classes": 0,
      "summary": "Generator modules for creating LLMStruct JSON outputs from parsed code data."
    },
    {
      "module_id": "src.llmstruct.parsers.javascript_parser",
      "path": "src\\llmstruct\\parsers\\javascript_parser.py",
      "category": "core",
      "functions": 5,
      "classes": 1,
      "summary": ""
    },
    {
      "module_id": "src.llmstruct.parsers.python_parser",
      "path": "src\\llmstruct\\parsers\\python_parser.py",
      "category": "core",
      "functions": 9,
      "classes": 1,
      "summary": ""
    },
    {
      "module_id": "src.llmstruct.parsers.__init__",
      "path": "src\\llmstruct\\parsers\\__init__.py",
      "category": "cli",
      "functions": 0,
      "classes": 0,
      "summary": "Language-specific parsers for extracting code structure data for LLMStruct JSON."
    },
    {
      "module_id": "src.llmstruct.templates.__init__",
      "path": "src\\llmstruct\\templates\\__init__.py",
      "category": "cli",
      "functions": 0,
      "classes": 0,
      "summary": "Templates for LLM prompts used in LLMStruct integration."
    },
    {
      "module_id": "src.llmstruct.validators.json_validator",
      "path": "src\\llmstruct\\validators\\json_validator.py",
      "category": "core",
      "functions": 1,
      "classes": 0,
      "summary": ""
    },
    {
      "module_id": "src.llmstruct.validators.__init__",
      "path": "src\\llmstruct\\validators\\__init__.py",
      "category": "cli",
      "functions": 0,
      "classes": 0,
      "summary": "Validation modules for ensuring LLMStruct JSON complies with the schema."
    }
  ],
  "modules": [
    {
      "module_id": "collector",
      "path": "collector.py",
      "category": "core",
      "module_doc": "",
      "functions": [
        {
          "name": "load_gitignore",
          "docstring": "",
          "line_range": [
            10,
            14
          ],
          "parameters": [],
          "decorators": []
        },
        {
          "name": "is_text_file",
          "docstring": "Check if file is likely a text file based on extension.",
          "line_range": [
            16,
            19
          ],
          "parameters": [
            "file_path"
          ],
          "decorators": []
        },
        {
          "name": "collect_project",
          "docstring": "",
          "line_range": [
            21,
            44
          ],
          "parameters": [],
          "decorators": []
        }
      ],
      "classes": [],
      "callgraph": {
        "load_gitignore": [
          "Path",
          "gitignore_path.exists",
          "gitignore_parser.parse_gitignore"
        ],
        "is_text_file": [],
        "collect_project": [
          "is_text_file",
          "open",
          "gitignore",
          "f.read",
          "logger.info",
          "len",
          "doc_files.items",
          "str",
          "file_path.is_file",
          "json.dump",
          "logger.error",
          "any",
          "logger.warning",
          "root_dir.rglob",
          "Path",
          "load_gitignore"
        ]
      },
      "dependencies": [
        "Path",
        "gitignore_parser",
        "json",
        "logging",
        "pathlib"
      ],
      "hash": null
    },
    {
      "module_id": "test_efficiency",
      "path": "test_efficiency.py",
      "category": "test",
      "module_doc": "",
      "functions": [
        {
          "name": "get_system_metrics",
          "docstring": "",
          "line_range": [
            14,
            18
          ],
          "parameters": [],
          "decorators": []
        },
        {
          "name": "is_local_address",
          "docstring": "",
          "line_range": [
            20,
            26
          ],
          "parameters": [
            "url"
          ],
          "decorators": []
        },
        {
          "name": "setup_proxy",
          "docstring": "",
          "line_range": [
            28,
            31
          ],
          "parameters": [
            "proxy_url"
          ],
          "decorators": []
        },
        {
          "name": "check_ollama",
          "docstring": "",
          "line_range": [
            33,
            38
          ],
          "parameters": [
            "api_url"
          ],
          "decorators": []
        },
        {
          "name": "optimize_prompt",
          "docstring": "",
          "line_range": [
            40,
            45
          ],
          "parameters": [
            "struct_data",
            "max_tokens"
          ],
          "decorators": []
        },
        {
          "name": "run_llm_request",
          "docstring": "",
          "line_range": [
            47,
            71
          ],
          "parameters": [
            "api_url",
            "payload",
            "proxy"
          ],
          "decorators": []
        },
        {
          "name": "check_llmstruct_cli",
          "docstring": "",
          "line_range": [
            73,
            74
          ],
          "parameters": [],
          "decorators": []
        },
        {
          "name": "test_with_llmstruct",
          "docstring": "",
          "line_range": [
            76,
            102
          ],
          "parameters": [
            "api_url",
            "project_path",
            "proxy",
            "use_placeholder"
          ],
          "decorators": []
        },
        {
          "name": "test_without_llmstruct",
          "docstring": "",
          "line_range": [
            104,
            111
          ],
          "parameters": [
            "api_url",
            "project_path",
            "proxy"
          ],
          "decorators": []
        },
        {
          "name": "test_with_grok",
          "docstring": "",
          "line_range": [
            113,
            135
          ],
          "parameters": [
            "api_key",
            "project_path",
            "proxy",
            "use_placeholder"
          ],
          "decorators": []
        },
        {
          "name": "evaluate_accuracy",
          "docstring": "",
          "line_range": [
            137,
            139
          ],
          "parameters": [
            "response_text",
            "expected"
          ],
          "decorators": []
        },
        {
          "name": "main",
          "docstring": "",
          "line_range": [
            141,
            188
          ],
          "parameters": [],
          "decorators": []
        }
      ],
      "classes": [],
      "callgraph": {
        "get_system_metrics": [
          "psutil.virtual_memory",
          "psutil.cpu_percent"
        ],
        "is_local_address": [
          "ipaddress.ip_address",
          "urlparse"
        ],
        "setup_proxy": [
          "os.getenv"
        ],
        "check_ollama": [
          "response.json",
          "api_url.replace",
          "str",
          "requests.get"
        ],
        "optimize_prompt": [
          "len",
          "print",
          "struct_data.split"
        ],
        "run_llm_request": [
          "print",
          "len",
          "type",
          "is_local_address",
          "time.perf_counter",
          "requests.Session",
          "response.raise_for_status",
          "get_system_metrics",
          "response.json",
          "session.post"
        ],
        "check_llmstruct_cli": [
          "shutil.which"
        ],
        "test_with_llmstruct": [
          "open",
          "f.read",
          "optimize_prompt",
          "str",
          "json.dump",
          "run_llm_request",
          "subprocess.run",
          "target_path.exists",
          "check_llmstruct_cli",
          "Path",
          "FileNotFoundError"
        ],
        "test_without_llmstruct": [
          "open",
          "f.read",
          "optimize_prompt",
          "run_llm_request",
          "Path"
        ],
        "test_with_grok": [
          "open",
          "f.read",
          "optimize_prompt",
          "json.dump",
          "target_path.exists",
          "test_grok",
          "Path",
          "FileNotFoundError"
        ],
        "evaluate_accuracy": [
          "len",
          "response_text.lower",
          "sum"
        ],
        "main": [
          "print",
          "test_without_llmstruct",
          "open",
          "check_ollama",
          "range",
          "parser.parse_args",
          "str",
          "test_with_grok",
          "json.dump",
          "argparse.ArgumentParser",
          "parser.add_argument",
          "test_with_llmstruct",
          "evaluate_accuracy",
          "check_llmstruct_cli",
          "setup_proxy"
        ]
      },
      "dependencies": [
        "Path",
        "argparse",
        "ipaddress",
        "json",
        "os",
        "pathlib",
        "psutil",
        "requests",
        "shutil",
        "src.llmstruct.grok",
        "subprocess",
        "test_grok",
        "time",
        "urllib.parse",
        "urlparse"
      ],
      "hash": null
    },
    {
      "module_id": "verify_llm_response",
      "path": "verify_llm_response.py",
      "category": "core",
      "module_doc": "",
      "functions": [
        {
          "name": "load_json_file",
          "docstring": "Load a JSON file and return its contents.",
          "line_range": [
            12,
            22
          ],
          "parameters": [
            "file_path"
          ],
          "decorators": []
        },
        {
          "name": "verify_response_with_struct",
          "docstring": "Verify llm_response.json against struct.json.",
          "line_range": [
            24,
            58
          ],
          "parameters": [
            "response_text",
            "struct_data"
          ],
          "decorators": []
        },
        {
          "name": "verify_response_without_struct",
          "docstring": "Verify llm_response.json based on LLMstruct principles.",
          "line_range": [
            60,
            90
          ],
          "parameters": [
            "response_text"
          ],
          "decorators": []
        },
        {
          "name": "generate_metrics",
          "docstring": "Generate metrics for the response per EXT-004.",
          "line_range": [
            92,
            120
          ],
          "parameters": [
            "response_data",
            "server_log"
          ],
          "decorators": []
        },
        {
          "name": "update_tasks_json",
          "docstring": "Append a new task to tasks.json.",
          "line_range": [
            122,
            129
          ],
          "parameters": [
            "tasks_file",
            "new_task"
          ],
          "decorators": []
        },
        {
          "name": "main",
          "docstring": "",
          "line_range": [
            131,
            193
          ],
          "parameters": [],
          "decorators": []
        }
      ],
      "classes": [],
      "callgraph": {
        "load_json_file": [
          "logging.error",
          "json.load",
          "open"
        ],
        "verify_response_with_struct": [
          "logging.error",
          "e.startswith",
          "logging.info",
          "expected_extensions.issubset",
          "struct_data.get",
          "expected_files.issubset",
          "expected_goals.issubset",
          "re.findall",
          "set"
        ],
        "verify_response_without_struct": [
          "logging.error",
          "response_text.lower",
          "logging.info",
          "expected_extensions.issubset",
          "expected_files.issubset",
          "principle.lower",
          "expected_goals.issubset",
          "re.findall",
          "set"
        ],
        "generate_metrics": [
          "response_text.split",
          "len",
          "server_log.get",
          "datetime.utcnow",
          "re.findall"
        ],
        "update_tasks_json": [
          "open",
          "logging.info",
          "load_json_file",
          "json.dump",
          "tasks.get"
        ],
        "main": [
          "open",
          "logging.info",
          "parser.parse_args",
          "load_json_file",
          "verify_response_with_struct",
          "json.dump",
          "argparse.ArgumentParser",
          "parser.add_argument",
          "update_tasks_json",
          "verify_response_without_struct",
          "generate_metrics"
        ]
      },
      "dependencies": [
        "Any",
        "Dict",
        "Optional",
        "argparse",
        "datetime",
        "json",
        "logging",
        "os",
        "re",
        "typing"
      ],
      "hash": null
    },
    {
      "module_id": "examples.python_project_main",
      "path": "examples\\python_project_main.py",
      "category": "core",
      "module_doc": "Main module for the sample project.",
      "functions": [
        {
          "name": "main",
          "docstring": "Run the program.",
          "line_range": [
            5,
            8
          ],
          "parameters": [],
          "decorators": []
        },
        {
          "name": "run",
          "docstring": "Execute the app.",
          "line_range": [
            12,
            14
          ],
          "parameters": [
            "self"
          ],
          "decorators": []
        }
      ],
      "classes": [
        {
          "name": "App",
          "docstring": "Application class.",
          "line_range": [
            10,
            14
          ],
          "methods": [
            {
              "name": "run",
              "docstring": "Execute the app.",
              "line_range": [
                12,
                14
              ],
              "parameters": [
                "self"
              ]
            }
          ],
          "bases": []
        }
      ],
      "callgraph": {
        "main": [
          "print",
          "utils.helper"
        ],
        "run": [
          "utils.log"
        ]
      },
      "dependencies": [
        "utils"
      ],
      "hash": null
    },
    {
      "module_id": "examples.python_project_utils",
      "path": "examples\\python_project_utils.py",
      "category": "core",
      "module_doc": "Utility functions for the sample project.",
      "functions": [
        {
          "name": "helper",
          "docstring": "Help the main function.",
          "line_range": [
            5,
            7
          ],
          "parameters": [],
          "decorators": []
        },
        {
          "name": "log",
          "docstring": "Log a message.",
          "line_range": [
            9,
            11
          ],
          "parameters": [
            "message"
          ],
          "decorators": []
        }
      ],
      "classes": [],
      "callgraph": {
        "helper": [
          "log"
        ],
        "log": [
          "logging.info"
        ]
      },
      "dependencies": [
        "logging"
      ],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.cli",
      "path": "src\\llmstruct\\cli.py",
      "category": "core",
      "module_doc": "",
      "functions": [
        {
          "name": "load_gitignore",
          "docstring": "Load and normalize patterns from .gitignore.",
          "line_range": [
            16,
            26
          ],
          "parameters": [
            "root_dir"
          ],
          "decorators": []
        },
        {
          "name": "load_config",
          "docstring": "Load settings from llmstruct.toml or return empty dict.",
          "line_range": [
            28,
            37
          ],
          "parameters": [
            "root_dir"
          ],
          "decorators": []
        },
        {
          "name": "parse",
          "docstring": "Parse codebase and generate struct.json.",
          "line_range": [
            39,
            75
          ],
          "parameters": [
            "args"
          ],
          "decorators": []
        },
        {
          "name": "query",
          "docstring": "Query LLMs with prompt and context.",
          "line_range": [
            77,
            95
          ],
          "parameters": [
            "args"
          ],
          "decorators": []
        },
        {
          "name": "context",
          "docstring": "Generate context.json from input JSON.",
          "line_range": [
            97,
            99
          ],
          "parameters": [
            "args"
          ],
          "decorators": []
        },
        {
          "name": "dogfood",
          "docstring": "Run dogfooding analysis.",
          "line_range": [
            101,
            103
          ],
          "parameters": [
            "args"
          ],
          "decorators": []
        },
        {
          "name": "review",
          "docstring": "Review codebase with LLM.",
          "line_range": [
            105,
            107
          ],
          "parameters": [
            "args"
          ],
          "decorators": []
        },
        {
          "name": "main",
          "docstring": "Command-line interface for LLMstruct.",
          "line_range": [
            109,
            162
          ],
          "parameters": [],
          "decorators": []
        }
      ],
      "classes": [],
      "callgraph": {
        "load_gitignore": [
          "line.strip",
          "logging.error",
          "gitignore_path.exists",
          "line.startswith",
          "Path",
          "gitignore_path.open"
        ],
        "load_config": [
          "logging.error",
          "config_path.exists",
          "config_path.open",
          "Path",
          "toml.load"
        ],
        "parse": [
          "generate_json",
          "logging.error",
          "logging.info",
          "config.get",
          "load_config",
          "json.dump",
          "Path",
          "load_gitignore",
          "logging.warning"
        ],
        "query": [
          "logging.error",
          "logging.info",
          "json.dump",
          "client.query",
          "LLMClient",
          "Path"
        ],
        "context": [
          "logging.warning"
        ],
        "dogfood": [
          "logging.warning"
        ],
        "review": [
          "logging.warning"
        ],
        "main": [
          "review_parser.add_argument",
          "query",
          "query_parser.add_argument",
          "parser.parse_args",
          "context_parser.add_argument",
          "parse",
          "parser.add_subparsers",
          "context",
          "subparsers.add_parser",
          "review",
          "argparse.ArgumentParser",
          "parse_parser.add_argument",
          "dogfood",
          "dogfood_parser.add_argument",
          "asyncio.run"
        ]
      },
      "dependencies": [
        "LLMClient",
        "List",
        "Optional",
        "Path",
        "argparse",
        "asyncio",
        "generate_json",
        "json",
        "llmstruct",
        "llmstruct.generators.json_generator",
        "logging",
        "os",
        "pathlib",
        "toml",
        "typing"
      ],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.grok",
      "path": "src\\llmstruct\\grok.py",
      "category": "core",
      "module_doc": "",
      "functions": [
        {
          "name": "test_grok",
          "docstring": "",
          "line_range": [
            22,
            28
          ],
          "parameters": [
            "api_key",
            "prompt",
            "proxy"
          ],
          "decorators": []
        },
        {
          "name": "__init__",
          "docstring": "",
          "line_range": [
            5,
            10
          ],
          "parameters": [
            "self",
            "api_key",
            "proxy"
          ],
          "decorators": []
        },
        {
          "name": "generate",
          "docstring": "",
          "line_range": [
            12,
            20
          ],
          "parameters": [
            "self",
            "prompt",
            "model"
          ],
          "decorators": []
        }
      ],
      "classes": [
        {
          "name": "GrokClient",
          "docstring": "",
          "line_range": [
            4,
            20
          ],
          "methods": [
            {
              "name": "__init__",
              "docstring": "",
              "line_range": [
                5,
                10
              ],
              "parameters": [
                "self",
                "api_key",
                "proxy"
              ]
            },
            {
              "name": "generate",
              "docstring": "",
              "line_range": [
                12,
                20
              ],
              "parameters": [
                "self",
                "prompt",
                "model"
              ]
            }
          ],
          "bases": []
        }
      ],
      "callgraph": {
        "__init__": [
          "requests.Session"
        ],
        "generate": [
          "response.json",
          "response.raise_for_status",
          "len",
          "prompt.split"
        ],
        "test_grok": [
          "client.generate",
          "time.perf_counter",
          "GrokClient"
        ]
      },
      "dependencies": [
        "os",
        "requests"
      ],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.llm_client",
      "path": "src\\llmstruct\\llm_client.py",
      "category": "core",
      "module_doc": "",
      "functions": [
        {
          "name": "__init__",
          "docstring": "Initialize LLMClient with optional Ollama host.",
          "line_range": [
            30,
            36
          ],
          "parameters": [
            "self",
            "ollama_host"
          ],
          "decorators": []
        },
        {
          "name": "query",
          "docstring": "Query LLMs with prompt, context, and optional model.",
          "line_range": [
            38,
            86
          ],
          "parameters": [
            "self",
            "prompt",
            "context_path",
            "mode",
            "model",
            "artifact_ids"
          ],
          "decorators": []
        },
        {
          "name": "_query_grok",
          "docstring": "Query Grok API.",
          "line_range": [
            88,
            111
          ],
          "parameters": [
            "self",
            "prompt"
          ],
          "decorators": []
        },
        {
          "name": "_query_anthropic",
          "docstring": "Query Anthropic API.",
          "line_range": [
            113,
            137
          ],
          "parameters": [
            "self",
            "prompt"
          ],
          "decorators": []
        },
        {
          "name": "_query_ollama",
          "docstring": "Query Ollama API with specified model.",
          "line_range": [
            139,
            156
          ],
          "parameters": [
            "self",
            "prompt",
            "model"
          ],
          "decorators": []
        },
        {
          "name": "_query_hybrid",
          "docstring": "Query multiple LLMs and combine results.",
          "line_range": [
            158,
            168
          ],
          "parameters": [
            "self",
            "prompt",
            "model"
          ],
          "decorators": []
        }
      ],
      "classes": [
        {
          "name": "LLMClient",
          "docstring": "",
          "line_range": [
            29,
            168
          ],
          "methods": [
            {
              "name": "__init__",
              "docstring": "Initialize LLMClient with optional Ollama host.",
              "line_range": [
                30,
                36
              ],
              "parameters": [
                "self",
                "ollama_host"
              ]
            },
            {
              "name": "query",
              "docstring": "Query LLMs with prompt, context, and optional model.",
              "line_range": [
                38,
                86
              ],
              "parameters": [
                "self",
                "prompt",
                "context_path",
                "mode",
                "model",
                "artifact_ids"
              ]
            },
            {
              "name": "_query_grok",
              "docstring": "Query Grok API.",
              "line_range": [
                88,
                111
              ],
              "parameters": [
                "self",
                "prompt"
              ]
            },
            {
              "name": "_query_anthropic",
              "docstring": "Query Anthropic API.",
              "line_range": [
                113,
                137
              ],
              "parameters": [
                "self",
                "prompt"
              ]
            },
            {
              "name": "_query_ollama",
              "docstring": "Query Ollama API with specified model.",
              "line_range": [
                139,
                156
              ],
              "parameters": [
                "self",
                "prompt",
                "model"
              ]
            },
            {
              "name": "_query_hybrid",
              "docstring": "Query multiple LLMs and combine results.",
              "line_range": [
                158,
                168
              ],
              "parameters": [
                "self",
                "prompt",
                "model"
              ]
            }
          ],
          "bases": []
        }
      ],
      "callgraph": {
        "__init__": [
          "os.getenv",
          "int",
          "logging.info"
        ],
        "query": [
          "asyncio.sleep",
          "json.load",
          "self._query_ollama",
          "logging.error",
          "range",
          "logging.info",
          "self._query_anthropic",
          "self._query_grok",
          "Path",
          "self._query_hybrid",
          "json.dumps",
          "logging.warning"
        ],
        "_query_grok": [
          "logging.error",
          "aiohttp.ClientSession",
          "logging.info",
          "response.json",
          "session.post",
          "result.get"
        ],
        "_query_anthropic": [
          "logging.error",
          "aiohttp.ClientSession",
          "logging.info",
          "response.json",
          "session.post",
          "result.get"
        ],
        "_query_ollama": [
          "logging.debug",
          "logging.error",
          "aiohttp.ClientSession",
          "logging.info",
          "response.json",
          "session.post",
          "result.get"
        ],
        "_query_hybrid": [
          "self._query_ollama",
          "len",
          "logging.info",
          "isinstance",
          "self._query_grok",
          "asyncio.gather",
          "self._query_anthropic"
        ]
      },
      "dependencies": [
        "List",
        "Optional",
        "Path",
        "aiohttp",
        "asyncio",
        "dotenv",
        "json",
        "load_dotenv",
        "logging",
        "os",
        "pathlib",
        "requests",
        "typing",
        "urljoin",
        "urllib.parse"
      ],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.self_run",
      "path": "src\\llmstruct\\self_run.py",
      "category": "core",
      "module_doc": "",
      "functions": [
        {
          "name": "filter_json",
          "docstring": "Filter JSON to include only modules/functions relevant to the query.",
          "line_range": [
            5,
            25
          ],
          "parameters": [
            "struct",
            "query"
          ],
          "decorators": []
        },
        {
          "name": "attach_to_llm_request",
          "docstring": "Attach filtered JSON structure to LLM prompt.",
          "line_range": [
            27,
            32
          ],
          "parameters": [
            "json_path",
            "prompt"
          ],
          "decorators": []
        }
      ],
      "classes": [],
      "callgraph": {
        "filter_json": [
          "module.get",
          "k.lower",
          "query.lower",
          "re.findall"
        ],
        "attach_to_llm_request": [
          "filter_json",
          "json.dumps",
          "open",
          "json.load"
        ]
      },
      "dependencies": [
        "Any",
        "Dict",
        "json",
        "re",
        "typing"
      ],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.__init__",
      "path": "src\\llmstruct\\__init__.py",
      "category": "cli",
      "module_doc": "",
      "functions": [],
      "classes": [],
      "callgraph": {},
      "dependencies": [
        "LLMClient",
        "llm_client"
      ],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.__main__",
      "path": "src\\llmstruct\\__main__.py",
      "category": "cli",
      "module_doc": "",
      "functions": [],
      "classes": [],
      "callgraph": {},
      "dependencies": [
        "LLMClient",
        "llm_client",
        "llmstruct.cli",
        "main"
      ],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.generators.json_generator",
      "path": "src\\llmstruct\\generators\\json_generator.py",
      "category": "core",
      "module_doc": "",
      "functions": [
        {
          "name": "get_folder_structure",
          "docstring": "Capture directory and file structure, respecting .gitignore and patterns.",
          "line_range": [
            12,
            42
          ],
          "parameters": [
            "root_dir",
            "gitignore_patterns",
            "include_patterns",
            "exclude_patterns",
            "exclude_dirs"
          ],
          "decorators": []
        },
        {
          "name": "build_toc_and_modules",
          "docstring": "Build TOC and modules with robust .gitignore and directory filtering.",
          "line_range": [
            44,
            73
          ],
          "parameters": [
            "root_dir",
            "include_patterns",
            "exclude_patterns",
            "gitignore_patterns",
            "include_ranges",
            "include_hashes",
            "exclude_dirs"
          ],
          "decorators": []
        },
        {
          "name": "generate_json",
          "docstring": "Generate JSON structure for project.",
          "line_range": [
            75,
            113
          ],
          "parameters": [
            "root_dir",
            "include_patterns",
            "exclude_patterns",
            "gitignore_patterns",
            "include_ranges",
            "include_hashes",
            "goals",
            "exclude_dirs"
          ],
          "decorators": []
        }
      ],
      "classes": [],
      "callgraph": {
        "get_folder_structure": [
          "os.walk",
          "file_path.match",
          "str",
          "file_path.relative_to",
          "structure.append",
          "p.endswith",
          "any",
          "sorted",
          "Path",
          "p.rstrip",
          "set"
        ],
        "build_toc_and_modules": [
          "toc.append",
          "len",
          "f.match",
          "str",
          "p.endswith",
          "any",
          "modules.append",
          "Path",
          "analyze_module",
          "p.rstrip",
          "set"
        ],
        "generate_json": [
          "len",
          "get_folder_structure",
          "sum",
          "build_toc_and_modules",
          "list",
          "Path",
          "set"
        ]
      },
      "dependencies": [
        "Any",
        "Dict",
        "List",
        "Optional",
        "Path",
        "analyze_module",
        "datetime",
        "json",
        "logging",
        "os",
        "parsers.python_parser",
        "pathlib",
        "typing"
      ],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.generators.__init__",
      "path": "src\\llmstruct\\generators\\__init__.py",
      "category": "cli",
      "module_doc": "Generator modules for creating LLMStruct JSON outputs from parsed code data.",
      "functions": [],
      "classes": [],
      "callgraph": {},
      "dependencies": [
        "generate_json",
        "json_generator"
      ],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.parsers.javascript_parser",
      "path": "src\\llmstruct\\parsers\\javascript_parser.py",
      "category": "core",
      "module_doc": "",
      "functions": [
        {
          "name": "__init__",
          "docstring": "",
          "line_range": [
            8,
            12
          ],
          "parameters": [
            "self"
          ],
          "decorators": []
        },
        {
          "name": "file_hash",
          "docstring": "",
          "line_range": [
            14,
            19
          ],
          "parameters": [
            "self",
            "filepath"
          ],
          "decorators": []
        },
        {
          "name": "compute_file_metadata",
          "docstring": "",
          "line_range": [
            21,
            35
          ],
          "parameters": [
            "self",
            "filepath",
            "include_hashes"
          ],
          "decorators": []
        },
        {
          "name": "parse_module",
          "docstring": "",
          "line_range": [
            37,
            89
          ],
          "parameters": [
            "self",
            "filepath",
            "root_dir",
            "include_ranges",
            "include_hashes"
          ],
          "decorators": []
        },
        {
          "name": "extract_signature",
          "docstring": "",
          "line_range": [
            61,
            63
          ],
          "parameters": [
            "node"
          ],
          "decorators": []
        }
      ],
      "classes": [
        {
          "name": "JavaScriptParser",
          "docstring": "",
          "line_range": [
            7,
            89
          ],
          "methods": [
            {
              "name": "__init__",
              "docstring": "",
              "line_range": [
                8,
                12
              ],
              "parameters": [
                "self"
              ]
            },
            {
              "name": "file_hash",
              "docstring": "",
              "line_range": [
                14,
                19
              ],
              "parameters": [
                "self",
                "filepath"
              ]
            },
            {
              "name": "compute_file_metadata",
              "docstring": "",
              "line_range": [
                21,
                35
              ],
              "parameters": [
                "self",
                "filepath",
                "include_hashes"
              ]
            },
            {
              "name": "parse_module",
              "docstring": "",
              "line_range": [
                37,
                89
              ],
              "parameters": [
                "self",
                "filepath",
                "root_dir",
                "include_ranges",
                "include_hashes"
              ]
            }
          ],
          "bases": []
        }
      ],
      "callgraph": {
        "__init__": [
          "set"
        ],
        "file_hash": [
          "hashlib.sha256",
          "open",
          "f.read"
        ],
        "compute_file_metadata": [
          "os.stat",
          "self.file_hash",
          "open",
          "sum"
        ],
        "parse_module": [
          "open",
          "f.read",
          "esprima.parseModule",
          "str",
          "self.compute_file_metadata"
        ],
        "extract_signature": [
          "hasattr"
        ]
      },
      "dependencies": [
        "Any",
        "Dict",
        "List",
        "datetime",
        "esprima",
        "hashlib",
        "os",
        "typing"
      ],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.parsers.python_parser",
      "path": "src\\llmstruct\\parsers\\python_parser.py",
      "category": "core",
      "module_doc": "",
      "functions": [
        {
          "name": "infer_category",
          "docstring": "Infer module category based on its path.",
          "line_range": [
            10,
            17
          ],
          "parameters": [
            "file_path"
          ],
          "decorators": []
        },
        {
          "name": "compute_file_hash",
          "docstring": "Compute SHA-256 hash of file content.",
          "line_range": [
            64,
            71
          ],
          "parameters": [
            "file_path"
          ],
          "decorators": []
        },
        {
          "name": "analyze_module",
          "docstring": "Analyze Python module and return structured data.",
          "line_range": [
            73,
            130
          ],
          "parameters": [
            "file_path",
            "root_dir",
            "include_ranges",
            "include_hashes"
          ],
          "decorators": []
        },
        {
          "name": "__init__",
          "docstring": "",
          "line_range": [
            21,
            24
          ],
          "parameters": [
            "self"
          ],
          "decorators": []
        },
        {
          "name": "visit_Import",
          "docstring": "Capture import statements.",
          "line_range": [
            26,
            30
          ],
          "parameters": [
            "self",
            "node"
          ],
          "decorators": []
        },
        {
          "name": "visit_ImportFrom",
          "docstring": "Capture from-import statements.",
          "line_range": [
            32,
            38
          ],
          "parameters": [
            "self",
            "node"
          ],
          "decorators": []
        },
        {
          "name": "visit_FunctionDef",
          "docstring": "Track function definitions and their calls.",
          "line_range": [
            40,
            45
          ],
          "parameters": [
            "self",
            "node"
          ],
          "decorators": []
        },
        {
          "name": "visit_AsyncFunctionDef",
          "docstring": "Track async function definitions and their calls.",
          "line_range": [
            47,
            52
          ],
          "parameters": [
            "self",
            "node"
          ],
          "decorators": []
        },
        {
          "name": "visit_Call",
          "docstring": "Capture function calls.",
          "line_range": [
            54,
            62
          ],
          "parameters": [
            "self",
            "node"
          ],
          "decorators": []
        }
      ],
      "classes": [
        {
          "name": "CallVisitor",
          "docstring": "AST visitor to collect function calls and dependencies.",
          "line_range": [
            19,
            62
          ],
          "methods": [
            {
              "name": "__init__",
              "docstring": "",
              "line_range": [
                21,
                24
              ],
              "parameters": [
                "self"
              ]
            },
            {
              "name": "visit_Import",
              "docstring": "Capture import statements.",
              "line_range": [
                26,
                30
              ],
              "parameters": [
                "self",
                "node"
              ]
            },
            {
              "name": "visit_ImportFrom",
              "docstring": "Capture from-import statements.",
              "line_range": [
                32,
                38
              ],
              "parameters": [
                "self",
                "node"
              ]
            },
            {
              "name": "visit_FunctionDef",
              "docstring": "Track function definitions and their calls.",
              "line_range": [
                40,
                45
              ],
              "parameters": [
                "self",
                "node"
              ]
            },
            {
              "name": "visit_AsyncFunctionDef",
              "docstring": "Track async function definitions and their calls.",
              "line_range": [
                47,
                52
              ],
              "parameters": [
                "self",
                "node"
              ]
            },
            {
              "name": "visit_Call",
              "docstring": "Capture function calls.",
              "line_range": [
                54,
                62
              ],
              "parameters": [
                "self",
                "node"
              ]
            }
          ],
          "bases": [
            "ast.NodeVisitor"
          ]
        }
      ],
      "callgraph": {
        "infer_category": [
          "Path"
        ],
        "__init__": [
          "set"
        ],
        "visit_Import": [
          "self.generic_visit"
        ],
        "visit_ImportFrom": [
          "self.generic_visit"
        ],
        "visit_FunctionDef": [
          "self.generic_visit",
          "set"
        ],
        "visit_AsyncFunctionDef": [
          "self.generic_visit",
          "set"
        ],
        "visit_Call": [
          "isinstance",
          "self.generic_visit"
        ],
        "compute_file_hash": [
          "hashlib.sha256",
          "open",
          "f.read",
          "logging.error"
        ],
        "analyze_module": [
          "functions.append",
          "ast.parse",
          "open",
          "f.read",
          "logging.error",
          "visitor.visit",
          "ast.get_docstring",
          "isinstance",
          "ast.unparse",
          "classes.append",
          "str",
          "sorted",
          "compute_file_hash",
          "CallVisitor",
          "list",
          "Path",
          "ast.walk",
          "infer_category"
        ]
      },
      "dependencies": [
        "Any",
        "Dict",
        "List",
        "Optional",
        "Path",
        "Set",
        "ast",
        "hashlib",
        "logging",
        "os",
        "pathlib",
        "typing"
      ],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.parsers.__init__",
      "path": "src\\llmstruct\\parsers\\__init__.py",
      "category": "cli",
      "module_doc": "Language-specific parsers for extracting code structure data for LLMStruct JSON.",
      "functions": [],
      "classes": [],
      "callgraph": {},
      "dependencies": [
        "JavaScriptParser",
        "analyze_module",
        "javascript_parser",
        "python_parser"
      ],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.templates.__init__",
      "path": "src\\llmstruct\\templates\\__init__.py",
      "category": "cli",
      "module_doc": "Templates for LLM prompts used in LLMStruct integration.",
      "functions": [],
      "classes": [],
      "callgraph": {},
      "dependencies": [],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.validators.json_validator",
      "path": "src\\llmstruct\\validators\\json_validator.py",
      "category": "core",
      "module_doc": "",
      "functions": [
        {
          "name": "validate_struct_json",
          "docstring": "",
          "line_range": [
            8,
            35
          ],
          "parameters": [
            "json_path",
            "schema_path"
          ],
          "decorators": []
        }
      ],
      "classes": [],
      "callgraph": {
        "validate_struct_json": [
          "json_file.exists",
          "validate",
          "logging.error",
          "open",
          "logging.info",
          "str",
          "schema_file.exists",
          "Path",
          "json.load"
        ]
      },
      "dependencies": [
        "Path",
        "ValidationError",
        "json",
        "jsonschema",
        "logging",
        "pathlib",
        "sys",
        "validate"
      ],
      "hash": null
    },
    {
      "module_id": "src.llmstruct.validators.__init__",
      "path": "src\\llmstruct\\validators\\__init__.py",
      "category": "cli",
      "module_doc": "Validation modules for ensuring LLMStruct JSON complies with the schema.",
      "functions": [],
      "classes": [],
      "callgraph": {},
      "dependencies": [
        "generate_json",
        "json_generator",
        "json_validator",
        "validate_struct_json"
      ],
      "hash": null
    }
  ]
}