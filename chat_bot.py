#!/usr/bin/env python3
"""
LLMStruct Chat Bot - –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å Cursor + Ollama
"""

import os
import json
import time
import logging
import aiohttp
import toml
from typing import Optional
from datetime import datetime
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

try:
    from telegram import Update, BotCommand
    from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
except ImportError:
    print("‚ùå Missing telegram dependencies. Install with: pip install python-telegram-bot")
    exit(1)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –±–æ—Ç–∞
try:
    import sys
    sys.path.append('.')
    from src.llmstruct.metrics_tracker import get_metrics_tracker, track_workflow_event, track_task_start, track_task_complete, track_token_usage
    METRICS_AVAILABLE = True
    logger.info("üìä Metrics system loaded")
except ImportError:
    METRICS_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Metrics system not available")

class LLMStructChatBot:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π —á–∞—Ç-–±–æ—Ç –¥–ª—è LLMStruct —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥–ª—è Cursor + Ollama"""
    
    def __init__(self, token: str):
        self.token = token
        self.application = Application.builder().token(token).build()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.logs_dir = Path("logs/telegram")
        self.logs_dir.mkdir(parents=True, exist_ok=True)
        
        # –§–∞–π–ª –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π (—á–∏—Ç–∞–µ–º—ã–π Cursor'–æ–º)
        self.messages_log = self.logs_dir / "user_messages.log"
        self.cursor_commands = self.logs_dir / "cursor_commands.log"
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Ollama
        self.load_ollama_config()
        
        self.setup_handlers()
        
        if METRICS_AVAILABLE:
            track_workflow_event("chat_bot_startup")
    
    def load_ollama_config(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é Ollama –∏–∑ llmstruct.toml"""
        try:
            config_path = Path("llmstruct.toml")
            if config_path.exists():
                config = toml.load(config_path)
                # –ß–∏—Ç–∞–µ–º –∏–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–µ–∫—Ü–∏–∏ [api]
                self.ollama_host = config.get("api", {}).get("ollama_host", "http://localhost:11434")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º mistral –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–æ–Ω –µ—Å—Ç—å —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
                self.ollama_model = config.get("api", {}).get("model", "mistral:latest")
                logger.info(f"ü¶ô Ollama config loaded: {self.ollama_host}, model: {self.ollama_model}")
            else:
                # Fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
                self.ollama_host = "http://192.168.88.50:11434"
                self.ollama_model = "mistral:latest"
                logger.warning(f"‚ö†Ô∏è Config file not found, using defaults: {self.ollama_host}, model: {self.ollama_model}")
                
            # –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            self.available_models = [
                "mistral:latest",
                "deepseek-coder:6.7b-instruct", 
                "deepseek-coder:6.7b",
                "nomic-embed-text:latest"
            ]
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load Ollama config: {e}")
            # Fallback –∑–Ω–∞—á–µ–Ω–∏—è
            self.ollama_host = "http://192.168.88.50:11434"
            self.ollama_model = "mistral:latest"
            self.available_models = ["mistral:latest"]
    
    async def query_ollama(self, message: str, context: str = "") -> str:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ Ollama –∏ –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç"""
        try:
            prompt = f"""–¢—ã - LLMStruct AI Assistant, —Ä–∞–±–æ—Ç–∞—é—â–∏–π —á–µ—Ä–µ–∑ Telegram –±–æ—Ç.
            
–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context if context else "–û–±—ã—á–Ω—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä"}

–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {message}

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å –ø–æ–ª–µ–∑–Ω—ã–º –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –∫–∞—Å–∞–µ—Ç—Å—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏, –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –∏–ª–∏ LLMStruct –ø—Ä–æ–µ–∫—Ç–∞ - –¥–∞–≤–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ—Ç–≤–µ—Ç—ã."""

            data = {
                "model": self.ollama_model,
                "prompt": prompt,
                "stream": False
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(f"{self.ollama_host}/api/generate", json=data, timeout=30) as response:
                    if response.status == 200:
                        result = await response.json()
                        ollama_response = result.get("response", "").strip()
                        
                        if METRICS_AVAILABLE:
                            # –¢—Ä–µ–∫–∏–Ω–≥ —Ç–æ–∫–µ–Ω–æ–≤
                            input_tokens = len(message.split())
                            output_tokens = len(ollama_response.split())
                            tracker = get_metrics_tracker()
                            tracker.track_token_usage("ollama", self.ollama_model, input_tokens, output_tokens)
                        
                        return ollama_response
                    else:
                        error_text = await response.text()
                        logger.error(f"‚ùå Ollama error {response.status}: {error_text}")
                        return f"‚ùå –û—à–∏–±–∫–∞ Ollama: {response.status}"
                        
        except Exception as e:
            error_msg = str(e)
            logger.error(f"‚ùå Ollama error: {error_msg}")
            
            if "timeout" in error_msg.lower():
                return "‚è∞ Ollama –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç (timeout 30s)"
            elif "connection" in error_msg.lower() or "cannot connect" in error_msg.lower():
                return f"üåê –ù–µ –º–æ–≥—É –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama: {error_msg}"
            else:
                return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Ollama: {error_msg}"
    
    def log_user_message(self, user_info: dict, message: str, message_type: str = "text", chat_id: int = None):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–∞–π–ª –¥–ª—è Cursor"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"""
=== {timestamp} ===
üë§ USER: {user_info.get('first_name', 'Unknown')} (@{user_info.get('username', 'unknown')})
üì± TYPE: {message_type}
üÜî CHAT_ID: {chat_id if chat_id else 'unknown'}
üí¨ MESSAGE: {message}
{'='*60}
"""
        
        with open(self.messages_log, 'a', encoding='utf-8') as f:
            f.write(log_entry)
        
        # –ï—Å–ª–∏ —ç—Ç–æ –∫–æ–º–∞–Ω–¥–∞ –¥–ª—è Cursor, –¥—É–±–ª–∏—Ä—É–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
        if any(keyword in message.lower() for keyword in ['cursor', 'claude', '–ø—Ä–æ–¥–æ–ª–∂–∏', 'continue', '–∏—Å–ø—Ä–∞–≤—å', 'fix']):
            with open(self.cursor_commands, 'a', encoding='utf-8') as f:
                f.write(f"{timestamp} | CURSOR COMMAND: {message}\n")
    
    def setup_handlers(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∫–æ–º–∞–Ω–¥"""
        self.application.add_handler(CommandHandler("start", self.start_command))
        self.application.add_handler(CommandHandler("help", self.help_command))
        self.application.add_handler(CommandHandler("status", self.status_command))
        self.application.add_handler(CommandHandler("metrics", self.metrics_command))
        self.application.add_handler(CommandHandler("dev", self.dev_command))
        self.application.add_handler(CommandHandler("cursor", self.cursor_command))
        self.application.add_handler(CommandHandler("logs", self.logs_command))
        self.application.add_handler(CommandHandler("ollama", self.ollama_command))
        self.application.add_handler(CommandHandler("model", self.model_command))
        self.application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_message))
    
    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /start"""
        if METRICS_AVAILABLE:
            track_workflow_event("bot_command", "start")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É
        user_info = {
            'first_name': update.effective_user.first_name,
            'username': update.effective_user.username
        }
        self.log_user_message(user_info, "/start", "command", update.effective_chat.id)
        
        user_name = update.effective_user.first_name
        welcome_message = f"""üëã –ü—Ä–∏–≤–µ—Ç, {user_name}!

üß† –Ø **LLMStruct Chat Bot** - —Ç–µ–ø–µ—Ä—å —Å Ollama! ü¶ô

**üéØ –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
‚Ä¢ ü¶ô **Ollama AI** - —É–º–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
‚Ä¢ üîÑ **–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏** - –ø–µ—Ä–µ–∫–ª—é—á–∞–π—Å—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏
‚Ä¢ üìù –õ–æ–≥–∏—Ä—É—é –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è Cursor'–∞
‚Ä¢ ü§ñ –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º
‚Ä¢ üìä –ü–æ–ª–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
‚Ä¢ üîß –†–µ–∂–∏–º —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞

**üìã –ö–æ–º–∞–Ω–¥—ã:**
/help - –≤—Å–µ –∫–æ–º–∞–Ω–¥—ã
/status - —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
/metrics - –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞
/ollama - —Å—Ç–∞—Ç—É—Å Ollama —Å–µ—Ä–≤–µ—Ä–∞
/model - –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ ({len(self.available_models)} –¥–æ—Å—Ç—É–ø–Ω–æ)
/cursor - –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å Cursor
/logs - –ø–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
/dev - —Ä–µ–∂–∏–º —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞

**üí¨ –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã:**
1. **–£–º–Ω—ã–π –¥–∏–∞–ª–æ–≥** - –ø—Ä–æ—Å—Ç–æ –ø–∏—à–∏ —Å–æ–æ–±—â–µ–Ω–∏—è, –æ—Ç–≤–µ—á—É —á–µ—Ä–µ–∑ Ollama! üß†
2. **–ö–æ–º–∞–Ω–¥—ã –¥–ª—è Cursor** - –∏—Å–ø–æ–ª—å–∑—É–π: "cursor", "claude", "–ø—Ä–æ–¥–æ–ª–∂–∏", "–∏—Å–ø—Ä–∞–≤—å"
3. **–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏** - –∏—Å–ø–æ–ª—å–∑—É–π /model –∏ –≤—ã–±–µ—Ä–∏ –Ω–æ–º–µ—Ä –º–æ–¥–µ–ª–∏

ü¶ô **–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å:** `{self.ollama_model}`
üåê **–°–µ—Ä–≤–µ—Ä:** `{self.ollama_host}`

üì± **–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:**
{chr(10).join([f"  {i+1}. {model}" for i, model in enumerate(self.available_models)])}

–í—Å–µ —Ç–≤–æ–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –≤ `logs/telegram/user_messages.log` üìÑ"""
        await update.message.reply_text(welcome_message, parse_mode='Markdown')
    
    async def cursor_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /cursor - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–∏ —Å Cursor"""
        if METRICS_AVAILABLE:
            track_workflow_event("bot_command", "cursor")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É
        user_info = {
            'first_name': update.effective_user.first_name,
            'username': update.effective_user.username
        }
        self.log_user_message(user_info, "/cursor", "command", update.effective_chat.id)
        
        cursor_text = """ü§ñ **–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å Cursor/Claude**

**üìù –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:**
‚Ä¢ –í—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è ‚Üí `logs/telegram/user_messages.log`
‚Ä¢ –ö–æ–º–∞–Ω–¥—ã –¥–ª—è Cursor ‚Üí `logs/telegram/cursor_commands.log`

**üéØ –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è Cursor:**
‚Ä¢ "cursor" - –ø—Ä—è–º–æ–µ –æ–±—Ä–∞—â–µ–Ω–∏–µ
‚Ä¢ "claude" - –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ AI
‚Ä¢ "–ø—Ä–æ–¥–æ–ª–∂–∏" / "continue" - –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–±–æ—Ç—É
‚Ä¢ "–∏—Å–ø—Ä–∞–≤—å" / "fix" - –∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É

**üí° –ü—Ä–∏–º–µ—Ä—ã –∫–æ–º–∞–Ω–¥:**
"Cursor, –ø–æ–∫–∞–∂–∏ —Å—Ç–∞—Ç—É—Å –º–µ—Ç—Ä–∏–∫"
"Claude, –∏—Å–ø—Ä–∞–≤—å –±–æ—Ç–∞"
"–ü—Ä–æ–¥–æ–ª–∂–∏ —Ä–∞–±–æ—Ç—É –Ω–∞–¥ API"

**üìä –°—Ç–∞—Ç—É—Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è:**
‚Ä¢ –§–∞–π–ª —Å–æ–æ–±—â–µ–Ω–∏–π: ‚úÖ –ê–∫—Ç–∏–≤–µ–Ω
‚Ä¢ –ö–æ–º–∞–Ω–¥—ã Cursor: ‚úÖ –û—Ç—Å–ª–µ–∂–∏–≤–∞—é—Ç—Å—è
‚Ä¢ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫: """ + ("‚úÖ –í–∫–ª—é—á–µ–Ω–∞" if METRICS_AVAILABLE else "‚ùå –û—Ç–∫–ª—é—á–µ–Ω–∞") + """

Cursor –º–æ–∂–µ—Ç —á–∏—Ç–∞—Ç—å —ç—Ç–∏ –ª–æ–≥–∏ –∏ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —Ç–≤–æ–∏ –∫–æ–º–∞–Ω–¥—ã! üöÄ
"""
        
        await update.message.reply_text(cursor_text, parse_mode='Markdown')
    
    async def logs_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /logs - –ø–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        if METRICS_AVAILABLE:
            track_workflow_event("bot_command", "logs")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É
        user_info = {
            'first_name': update.effective_user.first_name,
            'username': update.effective_user.username
        }
        self.log_user_message(user_info, "/logs", "command", update.effective_chat.id)
        
        try:
            # –ß–∏—Ç–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π
            if self.messages_log.exists():
                with open(self.messages_log, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏
                entries = content.split('===')[-6:-1]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –∑–∞–ø–∏—Å–µ–π
                
                logs_text = "üìÑ **–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è:**\n\n"
                for entry in entries:
                    if entry.strip():
                        lines = entry.strip().split('\n')
                        if len(lines) >= 3:
                            timestamp = lines[0]
                            message_line = next((line for line in lines if line.startswith('üí¨ MESSAGE:')), '')
                            if message_line:
                                message = message_line.replace('üí¨ MESSAGE:', '').strip()
                                logs_text += f"`{timestamp}` {message[:50]}{'...' if len(message) > 50 else ''}\n"
                
                logs_text += f"\nüìÅ **–ü–æ–ª–Ω—ã–µ –ª–æ–≥–∏:** `{self.messages_log}`"
            else:
                logs_text = "üìÑ –õ–æ–≥–∏ –ø–æ–∫–∞ –ø—É—Å—Ç—ã. –ù–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å!"
            
            await update.message.reply_text(logs_text, parse_mode='Markdown')
            
        except Exception as e:
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–æ–≥–æ–≤: {e}")
    
    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /help"""
        if METRICS_AVAILABLE:
            track_workflow_event("bot_command", "help")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É
        user_info = {
            'first_name': update.effective_user.first_name,
            'username': update.effective_user.username
        }
        self.log_user_message(user_info, "/help", "command", update.effective_chat.id)
        
        help_text = """üîß **LLMStruct Chat Bot - –ö–æ–º–∞–Ω–¥—ã**

**üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:**
/status - –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
/metrics - –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
/dev - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤

**ü§ñ –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å Cursor:**
/cursor - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏
/logs - –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è

**üí¨ –û–±—â–µ–Ω–∏–µ:**
–ü—Ä–æ—Å—Ç–æ –ø–∏—à–∏ –º–Ω–µ –≤–æ–ø—Ä–æ—Å—ã! –Ø –ø–æ–Ω–∏–º–∞—é:
‚Ä¢ –í–æ–ø—Ä–æ—Å—ã –æ –ø—Ä–æ–µ–∫—Ç–µ –∏ –∫–æ–¥–µ
‚Ä¢ –ü—Ä–æ—Å—å–±—ã –æ –ø–æ–º–æ—â–∏ —Å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–æ–π
‚Ä¢ –û–±—Å—É–∂–¥–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
‚Ä¢ –ö–æ–º–∞–Ω–¥—ã –¥–ª—è Cursor/Claude

**üéØ –ü—Ä–∏–º–µ—Ä—ã –∫–æ–º–∞–Ω–¥ –¥–ª—è Cursor:**
"Cursor, –ø–æ–∫–∞–∂–∏ —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"
"Claude, –∏—Å–ø—Ä–∞–≤—å –ø—Ä–æ–±–ª–µ–º—ã —Å –±–æ—Ç–æ–º"
"–ü—Ä–æ–¥–æ–ª–∂–∏ —Ä–∞–±–æ—Ç—É –Ω–∞–¥ API"

**üìà –ú–µ—Ç—Ä–∏–∫–∏:** """ + ("‚úÖ –í–∫–ª—é—á–µ–Ω—ã" if METRICS_AVAILABLE else "‚ùå –û—Ç–∫–ª—é—á–µ–Ω—ã") + """
**üìù –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:** ‚úÖ –ê–∫—Ç–∏–≤–Ω–æ
"""
        
        await update.message.reply_text(help_text, parse_mode='Markdown')
    
    async def status_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /status"""
        task_id = f"chat_bot_status_{int(time.time())}"
        
        if METRICS_AVAILABLE:
            track_task_start(task_id, "chat_bot_status_check")
            track_workflow_event("bot_command", "status")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É
        user_info = {
            'first_name': update.effective_user.first_name,
            'username': update.effective_user.username
        }
        self.log_user_message(user_info, "/status", "command", update.effective_chat.id)
        
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ API
            api_status = "‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
            try:
                import requests
                response = requests.get("http://localhost:8000/api/v1/system/health", timeout=2)
                if response.status_code == 200:
                    api_status = "‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç"
            except:
                pass
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ struct.json
            struct_file = Path("struct.json")
            struct_status = "‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
            if struct_file.exists():
                age_hours = (time.time() - struct_file.stat().st_mtime) / 3600
                if age_hours < 1:
                    struct_status = "‚úÖ –ê–∫—Ç—É–∞–ª—å–Ω—ã–π"
                elif age_hours < 6:
                    struct_status = "üü° –ù–µ–¥–∞–≤–Ω–∏–π"
                else:
                    struct_status = "‚ö†Ô∏è –£—Å—Ç–∞—Ä–µ–≤—à–∏–π"
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤
            logs_status = "‚úÖ –ê–∫—Ç–∏–≤–Ω–æ" if self.messages_log.exists() else "‚ùå –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ"
            cursor_logs_count = 0
            if self.cursor_commands.exists():
                with open(self.cursor_commands, 'r', encoding='utf-8') as f:
                    cursor_logs_count = len(f.readlines())
            
            current_time = datetime.now().strftime("%H:%M:%S")
            
            status_text = f"""üìä **–°—Ç–∞—Ç—É—Å LLMStruct System**

üåê **API Server:** {api_status}
üìÅ **struct.json:** {struct_status}
üìä **Metrics:** {"‚úÖ –ê–∫—Ç–∏–≤–Ω—ã" if METRICS_AVAILABLE else "‚ùå –û—Ç–∫–ª—é—á–µ–Ω—ã"}
ü§ñ **Chat Bot:** ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç
üìù **–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:** {logs_status}
üéØ **–ö–æ–º–∞–Ω–¥—ã Cursor:** {cursor_logs_count} –∑–∞–ø–∏—Å–µ–π
‚è∞ **–í—Ä–µ–º—è:** {current_time}

üîÑ **–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** —Ç–æ–ª—å–∫–æ —á—Ç–æ
"""
            
            if METRICS_AVAILABLE:
                # –î–æ–±–∞–≤–ª—è–µ–º –∫—Ä–∞—Ç–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏
                try:
                    tracker = get_metrics_tracker()
                    summary = tracker.get_session_summary()
                    status_text += f"""
üìà **–¢–µ–∫—É—â–∞—è —Å–µ—Å—Å–∏—è:**
‚Ä¢ ID: `{summary['session_id'][:8]}`
‚Ä¢ –í—Ä–µ–º—è: {summary['duration']:.0f}s
‚Ä¢ –¢–æ–∫–µ–Ω—ã: {summary['total_tokens']:,}
‚Ä¢ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {summary['efficiency_score']:.2f}/1.0
"""
                    track_task_complete(task_id, "success")
                except Exception as e:
                    status_text += f"\n‚ö†Ô∏è *–û—à–∏–±–∫–∞ –º–µ—Ç—Ä–∏–∫: {str(e)[:50]}*"
            
            await update.message.reply_text(status_text, parse_mode='Markdown')
            
        except Exception as e:
            if METRICS_AVAILABLE:
                track_task_complete(task_id, "failed", str(e))
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}")
    
    async def metrics_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /metrics"""
        if not METRICS_AVAILABLE:
            await update.message.reply_text("‚ùå –°–∏—Å—Ç–µ–º–∞ –º–µ—Ç—Ä–∏–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            return
        
        track_workflow_event("bot_command", "metrics")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É
        user_info = {
            'first_name': update.effective_user.first_name,
            'username': update.effective_user.username
        }
        self.log_user_message(user_info, "/metrics", "command", update.effective_chat.id)
        
        try:
            tracker = get_metrics_tracker()
            summary = tracker.get_session_summary()
            
            efficiency_emoji = "üü¢" if summary['efficiency_score'] > 0.8 else "üü°" if summary['efficiency_score'] > 0.6 else "üî¥"
            
            metrics_text = f"""üìä **–î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏**
**–°–µ—Å—Å–∏—è:** `{summary['session_id'][:8]}`

{efficiency_emoji} **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å:** {summary['efficiency_score']:.2f}/1.0
‚è± **–í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã:** {summary['duration']:.0f}s ({summary['duration']/60:.1f}m)
üî¢ **–¢–æ–∫–µ–Ω—ã:** {summary['total_tokens']:,}
üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ${summary['estimated_cost']:.4f}

üìã **–ó–∞–¥–∞—á–∏:**
‚Ä¢ –í—ã–ø–æ–ª–Ω–µ–Ω–æ: {summary['tasks_completed']}/{summary['tasks_total']}
‚Ä¢ –ü–æ–≤—Ç–æ—Ä—ã: {summary['retries']}
‚Ä¢ –û—à–∏–±–∫–∏: {summary['avoidable_errors']}

üõ§ **–ü—Ä–æ–±–ª–µ–º—ã:**
‚Ä¢ –õ–æ–∂–Ω—ã–µ –ø—É—Ç–∏: {summary['false_paths']}

üìù **–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:**
‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏—è: ‚úÖ –ê–∫—Ç–∏–≤–Ω–æ
‚Ä¢ –§–∞–π–ª: `{self.messages_log}`

üìà **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
"""
            
            if summary['efficiency_score'] < 0.7:
                metrics_text += "‚ö†Ô∏è –ù–∏–∑–∫–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∞–±–æ—Ç—ã\n"
            elif summary['efficiency_score'] > 0.9:
                metrics_text += "üéâ –û—Ç–ª–∏—á–Ω–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å!\n"
            else:
                metrics_text += "‚úÖ –•–æ—Ä–æ—à–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å\n"
                
            if summary['false_paths'] > 5:
                metrics_text += "üîç –ú–Ω–æ–≥–æ –ª–æ–∂–Ω—ã—Ö –ø—É—Ç–µ–π - —É—Ç–æ—á–Ω—è–π—Ç–µ –∑–∞–¥–∞—á–∏\n"
                
            if summary['avoidable_errors'] > 0:
                metrics_text += "‚ö° –ï—Å—Ç—å –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏–º—ã–µ –æ—à–∏–±–∫–∏ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n"
            
            await update.message.reply_text(metrics_text, parse_mode='Markdown')
            
        except Exception as e:
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {e}")
    
    async def dev_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /dev - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤"""
        if METRICS_AVAILABLE:
            track_workflow_event("bot_command", "dev")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É
        user_info = {
            'first_name': update.effective_user.first_name,
            'username': update.effective_user.username
        }
        self.log_user_message(user_info, "/dev", "command", update.effective_chat.id)
        
        dev_text = f"""üîß **Developer Information**

**üéØ –ü—Ä–æ–µ–∫—Ç:** LLMStruct AI-Enhanced Development Environment
**üìÇ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:** –õ–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞
**üêç Python:** 3.8+ —Å –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ–º

**üöÄ –î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã:**
‚Ä¢ CLI: `python -m llmstruct.cli`
‚Ä¢ API: `python test_api_simple.py`
‚Ä¢ Metrics: `python -m llmstruct.cli metrics`

**üìä –§–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞:**
‚Ä¢ `struct.json` - —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
‚Ä¢ `.metrics/` - –¥–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫
‚Ä¢ `src/llmstruct/` - –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥

**üìù –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ Telegram:**
‚Ä¢ –í—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è: `{self.messages_log}`
‚Ä¢ –ö–æ–º–∞–Ω–¥—ã Cursor: `{self.cursor_commands}`
‚Ä¢ –°—Ç–∞—Ç—É—Å: ‚úÖ –ê–∫—Ç–∏–≤–Ω–æ

**ü§ñ Bot Status:**
‚Ä¢ Token: ‚úÖ –ê–∫—Ç–∏–≤–µ–Ω
‚Ä¢ Metrics: """ + ("‚úÖ –í–∫–ª—é—á–µ–Ω—ã" if METRICS_AVAILABLE else "‚ùå –û—Ç–∫–ª—é—á–µ–Ω—ã") + """
‚Ä¢ Mode: Chat/Development + Cursor Integration

**üí° Useful Commands:**
`git status`, `python -m llmstruct.cli metrics status`

**üéØ Cursor Integration:**
–í—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –∏ –¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è —á—Ç–µ–Ω–∏—è AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º!
"""
        
        await update.message.reply_text(dev_text, parse_mode='Markdown')
    
    async def ollama_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /ollama - –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤—è–∑–∏ —Å Ollama"""
        if METRICS_AVAILABLE:
            track_workflow_event("bot_command", "ollama")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É
        user_info = {
            'first_name': update.effective_user.first_name,
            'username': update.effective_user.username
        }
        self.log_user_message(user_info, "/ollama", "command", update.effective_chat.id)
        
        await update.message.reply_text("üîç –ü—Ä–æ–≤–µ—Ä—è—é —Å–≤—è–∑—å —Å Ollama...")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Ollama
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.ollama_host}/api/tags", timeout=10) as response:
                    if response.status == 200:
                        data = await response.json()
                        models = data.get("models", [])
                        model_names = [m.get("name", "unknown") for m in models]
                        
                        ollama_text = f"""ü¶ô **Ollama Status**

üü¢ **–°–µ—Ä–≤–µ—Ä:** `{self.ollama_host}` - ‚úÖ –î–æ—Å—Ç—É–ø–µ–Ω
ü§ñ **–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å:** `{self.ollama_model}`

üìã **–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:**"""
                        
                        for model in model_names[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                            status = "‚úÖ" if model == self.ollama_model else "‚ö™"
                            ollama_text += f"\n‚Ä¢ {status} `{model}`"
                        
                        if len(model_names) > 5:
                            ollama_text += f"\n‚Ä¢ ... –∏ –µ—â—ë {len(model_names) - 5} –º–æ–¥–µ–ª–µ–π"
                        
                        if not model_names:
                            ollama_text += "\n‚ö†Ô∏è –ù–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
                        
                        # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
                        test_response = await self.query_ollama("–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ —Ç–µ—Å—Ç —Å–≤—è–∑–∏.")
                        if not test_response.startswith("‚ùå"):
                            ollama_text += f"""\n\nüß™ **–¢–µ—Å—Ç —Å–≤—è–∑–∏:** ‚úÖ –£—Å–ø–µ—à–Ω–æ
üìù **–û—Ç–≤–µ—Ç:** {test_response[:100]}{'...' if len(test_response) > 100 else ''}"""
                        else:
                            ollama_text += f"\n\nüß™ **–¢–µ—Å—Ç —Å–≤—è–∑–∏:** ‚ùå {test_response}"
                    
                    else:
                        ollama_text = f"""ü¶ô **Ollama Status**

üî¥ **–°–µ—Ä–≤–µ—Ä:** `{self.ollama_host}` - ‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–µ–Ω
üìä **–ö–æ–¥ –æ—à–∏–±–∫–∏:** {response.status}

üí° **–†–µ—à–µ–Ω–∏—è:**
‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω
‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –∞–¥—Ä–µ—Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ firewall/—Å–µ—Ç—å"""
            
            await update.message.reply_text(ollama_text, parse_mode='Markdown')
            
        except Exception as e:
            error_text = f"""ü¶ô **Ollama Status**

üî¥ **–°–µ—Ä–≤–µ—Ä:** `{self.ollama_host}` - ‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
‚ö†Ô∏è **–û—à–∏–±–∫–∞:** {str(e)}

üí° **–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:**
‚Ä¢ Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω
‚Ä¢ –ù–µ–≤–µ—Ä–Ω—ã–π –∞–¥—Ä–µ—Å —Å–µ—Ä–≤–µ—Ä–∞  
‚Ä¢ –ü—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ç—å—é
‚Ä¢ Timeout —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
            
            await update.message.reply_text(error_text, parse_mode='Markdown')
    
    async def model_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /model - –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ Ollama"""
        if METRICS_AVAILABLE:
            track_workflow_event("bot_command", "model")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É
        user_info = {
            'first_name': update.effective_user.first_name,
            'username': update.effective_user.username
        }
        self.log_user_message(user_info, "/model", "command", update.effective_chat.id)
        
        await update.message.reply_text("ü§î –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å Ollama:")
        
        model_options = "\n".join([f"{i+1}. {model}" for i, model in enumerate(self.available_models)])
        await update.message.reply_text(model_options, parse_mode='Markdown')
    
    async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å Ollama + –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        task_id = f"chat_bot_message_{int(time.time())}"
        
        if METRICS_AVAILABLE:
            track_task_start(task_id, "chat_bot_conversation")
            track_workflow_event("bot_command", "chat_message")
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_info = {
            'first_name': update.effective_user.first_name,
            'username': update.effective_user.username
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—Ç–≤–µ—Ç (reply)
        reply_context = ""
        if update.message.reply_to_message:
            original_text = update.message.reply_to_message.text or ""
            reply_context = f"–û—Ç–≤–µ—Ç –Ω–∞: {original_text[:100]}..."
        
        message_text = update.message.text
        self.log_user_message(user_info, message_text, "text", update.effective_chat.id)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –ø–æ –Ω–æ–º–µ—Ä—É
        if message_text.isdigit():
            model_num = int(message_text) - 1
            if 0 <= model_num < len(self.available_models):
                old_model = self.ollama_model
                self.ollama_model = self.available_models[model_num]
                
                if METRICS_AVAILABLE:
                    track_token_usage("ollama", self.ollama_model, 2, 35)
                    track_task_complete(task_id, "success")
                    
                await update.message.reply_text(
                    f"‚úÖ **–ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞**\n\n"
                    f"–ë—ã–ª–æ: `{old_model}`\n"
                    f"–°—Ç–∞–ª–æ: `{self.ollama_model}`\n\n"
                    f"ü¶ô –¢–µ–ø–µ—Ä—å –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –±—É–¥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è —á–µ—Ä–µ–∑ {self.ollama_model}",
                    parse_mode='Markdown'
                )
                return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–∞–Ω–¥—ã –¥–ª—è Cursor
        cursor_keywords = ["cursor", "claude", "–ø—Ä–æ–¥–æ–ª–∂–∏", "–∏—Å–ø—Ä–∞–≤—å", "–ø–æ–º–æ–≥–∏", "–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π"]
        is_cursor_command = any(keyword in message_text.lower() for keyword in cursor_keywords)
        
        if is_cursor_command:
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∫–∞–∫ –∫–æ–º–∞–Ω–¥—É –¥–ª—è Cursor
            cursor_log = f"logs/telegram/cursor_commands.log"
            Path(cursor_log).parent.mkdir(parents=True, exist_ok=True)
            
            with open(cursor_log, 'a', encoding='utf-8') as f:
                timestamp = datetime.now().strftime("%Y-%m-%dT%H:%M:%S")
                f.write(f"\n============================================================\n")
                f.write(f"üìÖ {timestamp}\n")
                f.write(f"üë§ {user_info['first_name']}\n")
                if reply_context:
                    f.write(f"üéØ {reply_context}\n")
                f.write(f"üìù {message_text}\n")
                f.write(f"============================================================\n")
            
            if METRICS_AVAILABLE:
                track_token_usage("cursor", "command", len(message_text.split()), 30)
                track_task_complete(task_id, "success")
                
            await update.message.reply_text(f"‚öôÔ∏è **Cursor AI –æ–±—Ä–∞–±–æ—Ç–∞–ª –∫–æ–º–∞–Ω–¥—É**\n\nüìù `{message_text[:100]}{'...' if len(message_text) > 100 else ''}`\n\n‚úÖ –ó–∞–¥–∞—á–∞ –ø–µ—Ä–µ–¥–∞–Ω–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫—É", parse_mode='Markdown')
            return
        
        # –û–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Ollama
        try:
            context_info = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {reply_context}" if reply_context else "–û–±—ã—á–Ω—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä"
            response = await self.query_ollama(message_text, context_info)
            
            if METRICS_AVAILABLE:
                track_token_usage("ollama", self.ollama_model, len(message_text.split()), len(response.split()))
                track_task_complete(task_id, "success")
                
            # –£–±–∏—Ä–∞–µ–º parse_mode —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å 400 Bad Request –∏–∑-–∑–∞ Markdown —Å–∏–º–≤–æ–ª–æ–≤
            await update.message.reply_text(response)
            
        except Exception as e:
            logger.error(f"‚ùå Error handling message: {e}")
            
            if METRICS_AVAILABLE:
                track_task_complete(task_id, "failed")
                
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {str(e)}")
    
    def run_sync(self):
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
        try:
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–æ–º–∞–Ω–¥ –±–æ—Ç–∞
            commands = [
                BotCommand("start", "üöÄ –ù–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É"),
                BotCommand("help", "‚ùì –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–º–æ—â—å"),
                BotCommand("status", "üìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"),
                BotCommand("metrics", "üìà –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏"),
                BotCommand("ollama", "ü¶ô –°—Ç–∞—Ç—É—Å Ollama —Å–µ—Ä–≤–µ—Ä–∞"),
                BotCommand("model", "üîÑ –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏"),
                BotCommand("dev", "üîß –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤"),
                BotCommand("cursor", "ü§ñ –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å Cursor"),
                BotCommand("logs", "üìÑ –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è"),
            ]
            
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(self.application.bot.set_my_commands(commands))
            
            logger.info("ü§ñ Starting LLMStruct Chat Bot...")
            if METRICS_AVAILABLE:
                tracker = get_metrics_tracker()
                logger.info(f"üìä Metrics session: {tracker.session_data['session_id']}")
            
            # –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
            self.application.run_polling(drop_pending_updates=True)
            
        except Exception as e:
            logger.error(f"‚ùå Bot startup failed: {e}")
            if METRICS_AVAILABLE:
                track_workflow_event("bot_error", str(e))
        finally:
            if METRICS_AVAILABLE:
                track_workflow_event("chat_bot_shutdown")
                tracker = get_metrics_tracker()
                tracker.save_session()
                logger.info("üìä Metrics saved")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ –±–æ—Ç–∞
    token = os.getenv('TELEGRAM_BOT_TOKEN')
    if not token:
        print("‚ùå Telegram bot token not found!")
        print("Set with: export TELEGRAM_BOT_TOKEN='your_token'")
        return
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ –±–æ—Ç–∞
    bot = LLMStructChatBot(token)
    bot.run_sync()

if __name__ == "__main__":
    main() 