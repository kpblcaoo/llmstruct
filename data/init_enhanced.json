{
  "metadata": {
    "project_name": "llmstruct",
    "description": "Universal JSON format for codebases with advanced LLM integration",
    "authors": [{"name": "@kpblcaoo", "github": "kpblcaoo"}],
    "license": "GPL-3.0",
    "version": "0.3.0",
    "artifact_id": "f8d2c9e3-7a1b-4f2c-9e7a-5c9d8e2f1b3d",
    "created_at": "2025-05-24T00:00:00Z",
    "updated_at": "2025-05-24T00:00:00Z"
  },
  
  "project_vision": {
    "core_mission": "Create a universal, LLM-optimized JSON format for codebase understanding and automation",
    "principles": [
      "Context-aware LLM interaction",
      "Minimal token consumption through smart context selection",
      "Automation-first CLI design",
      "Idempotent operations",
      "Artifact-based versioning"
    ],
    "goals": [
      "Universal JSON format for any codebase structure",
      "Seamless LLM integration with context optimization",
      "Queue-based automation for LLM-driven workflows",
      "Plugin-based extensibility for new languages",
      "RFC-documented open format"
    ]
  },

  "context_orchestration": {
    "description": "Smart context selection and usage rules for optimal LLM interaction",
    "context_hierarchy": {
      "level_1_essential": {
        "files": ["data/init.json"],
        "usage": "Always loaded first - provides project overview, goals, and context usage rules",
        "token_cost": "low",
        "scenarios": ["project introduction", "general questions", "CLI guidance"]
      },
      "level_2_structural": {
        "files": ["struct.json", "data/vision.json"],
        "usage": "Load when deep code analysis, navigation, or structural understanding is needed",
        "token_cost": "high",
        "scenarios": ["code analysis", "function/class search", "architecture questions", "refactoring"]
      },
      "level_3_operational": {
        "files": ["data/cli.json", "data/tasks.json", "data/artifacts_index.json"],
        "usage": "Load for automation, CLI operations, task management, and workflow orchestration",
        "token_cost": "medium", 
        "scenarios": ["CLI automation", "task planning", "workflow generation", "queue operations"]
      },
      "level_4_analytical": {
        "files": ["data/insights.json", "data/metrics.json", "schema/*.json"],
        "usage": "Load for analysis, optimization, validation, and improvement suggestions",
        "token_cost": "medium",
        "scenarios": ["performance analysis", "validation", "improvement suggestions", "metrics review"]
      }
    },
    "smart_selection_rules": [
      "For general chat: use only level_1_essential",
      "For code questions: combine level_1_essential + level_2_structural",
      "For CLI automation: combine level_1_essential + level_3_operational",
      "For project analysis: combine level_1_essential + level_4_analytical",
      "For complex workflows: combine relevant levels based on task requirements"
    ]
  },

  "cli_integration": {
    "interactive_mode": {
      "description": "Enhanced interactive CLI with LLM integration",
      "command_types": {
        "system_commands": {
          "prefix": "/",
          "examples": ["/view", "/write", "/scan", "/queue", "/cache"],
          "description": "Direct system operations, safe from LLM interference"
        },
        "llm_queries": {
          "prefix": "none",
          "description": "Natural language queries processed by LLM with smart context selection"
        }
      },
      "context_selection": {
        "default": "data/init.json",
        "fallback": "struct.json",
        "dynamic_loading": "Based on query type and content analysis"
      }
    },
    "queue_system": {
      "file": "data/cli_queue.json",
      "description": "LLM-generated command sequences for automation",
      "command_types": ["write", "scan", "llm", "validate", "analyze"],
      "safety_features": [
        "Filename sanitization",
        "Write restrictions to ./tmp",
        "Path validation",
        "Command validation against cli.json"
      ],
      "context_optimization": "Minimal context loading per command type"
    }
  },

  "cache_and_artifacts": {
    "cache_strategy": {
      "description": "JSONCache integration for performance optimization",
      "cache_levels": {
        "context_cache": "Frequently used context combinations",
        "query_cache": "LLM query results with context fingerprints",
        "structure_cache": "Parsed codebase structures"
      },
      "invalidation_triggers": [
        "File system changes",
        "Context file updates",
        "Schema changes"
      ]
    },
    "artifact_management": {
      "index_file": "data/artifacts_index.json",
      "versioning_strategy": "UUID-based with timestamp tracking",
      "storage_location": "data/artifacts/",
      "metadata_tracking": ["creation_time", "modification_time", "related_tasks", "context_usage"]
    }
  },

  "llm_optimization": {
    "token_management": {
      "strategies": [
        "Context-aware loading based on query analysis",
        "Incremental context building",
        "Smart filtering of irrelevant sections",
        "Caching of expensive context combinations"
      ],
      "thresholds": {
        "small_context": "< 4K tokens",
        "medium_context": "4K - 16K tokens",  
        "large_context": "16K - 32K tokens",
        "max_context": "< 128K tokens"
      }
    },
    "prompt_engineering": {
      "templates_location": "src/llmstruct/templates/",
      "context_injection_points": [
        "Project overview from init.json",
        "Relevant structure from struct.json",
        "Task context from tasks.json",
        "Command reference from cli.json"
      ]
    }
  },

  "automation_workflows": {
    "llm_driven_automation": {
      "description": "LLM can generate and execute command sequences",
      "workflow_types": {
        "code_analysis": ["scan", "analyze", "report"],
        "documentation": ["scan", "llm", "write"],
        "testing": ["scan", "validate", "test", "report"],
        "refactoring": ["scan", "analyze", "llm", "write", "validate"]
      },
      "safety_boundaries": [
        "All writes restricted to ./tmp",
        "No system command execution",
        "Read-only access to source code",
        "Validation against known command patterns"
      ]
    }
  },

  "json_ecosystem": {
    "core_files": {
      "init.json": {
        "purpose": "Master context and orchestration rules",
        "load_priority": "always_first",
        "update_frequency": "on_major_changes"
      },
      "struct.json": {
        "purpose": "Complete codebase structure and analysis",
        "load_priority": "on_demand_code_analysis",
        "update_frequency": "on_code_changes"
      },
      "cli.json": {
        "purpose": "CLI command reference and automation templates",
        "load_priority": "on_cli_operations",
        "update_frequency": "on_cli_changes"
      },
      "tasks.json": {
        "purpose": "Task management and project planning",
        "load_priority": "on_task_operations",
        "update_frequency": "on_task_updates"
      },
      "cli_queue.json": {
        "purpose": "Command queue for automation",
        "load_priority": "on_automation_requests",
        "update_frequency": "per_automation_cycle"
      }
    },
    "supporting_files": {
      "vision.json": "Project vision and strategic direction",
      "insights.json": "AI-generated insights and improvements",
      "metrics.json": "Project metrics and performance data",
      "artifacts_index.json": "Artifact tracking and versioning",
      "references.json": "External references and documentation links"
    },
    "schema_files": {
      "llmstruct_schema.json": "Main validation schema",
      "core.json": "Core structure definitions",
      "plugins/*.json": "Plugin-specific schemas"
    }
  },

  "usage_examples": {
    "basic_llm_interaction": {
      "scenario": "User asks general project question",
      "context_selection": ["init.json"],
      "example": "What is the goal of this project?"
    },
    "code_analysis": {
      "scenario": "User wants to understand code structure",
      "context_selection": ["init.json", "struct.json"],
      "example": "Show me all functions in the CLI module"
    },
    "automation_generation": {
      "scenario": "LLM generates command sequence",
      "context_selection": ["init.json", "cli.json", "tasks.json"],
      "example": "Generate commands to analyze and document the parser module"
    },
    "performance_optimization": {
      "scenario": "User wants performance insights",
      "context_selection": ["init.json", "metrics.json", "insights.json"],
      "example": "What performance improvements can be made?"
    }
  },

  "best_practices": {
    "for_llm_engineers": [
      "Always start with init.json for project understanding",
      "Use smart context selection to minimize token usage",
      "Leverage the queue system for complex automation",
      "Utilize artifact IDs for version tracking",
      "Follow safety boundaries for automated operations"
    ],
    "for_context_design": [
      "Keep init.json concise but comprehensive",
      "Use hierarchical context loading",
      "Implement context caching for performance",
      "Design for both human and LLM consumption",
      "Maintain clear relationships between JSON files"
    ],
    "for_automation": [
      "Use cli_queue.json for LLM-generated workflows",
      "Implement proper error handling and validation",
      "Restrict dangerous operations appropriately",
      "Cache expensive operations",
      "Log all automation activities"
    ]
  },

  "references": [
    {"path": "docs/llmstruct_format.md", "description": "Complete LLMStruct JSON format specification"},
    {"path": "docs/cli_commands.md", "description": "CLI command reference and examples"},
    {"path": "schema/llmstruct_schema.json", "description": "JSON schema for validation"},
    {"path": "data/vision.json", "description": "Project vision and strategic goals"},
    {"path": "src/llmstruct/cli.py", "description": "CLI implementation with queue processing"}
  ],

  "extension_points": {
    "new_json_files": "Follow the metadata structure and register in artifacts_index.json",
    "new_context_rules": "Add to context_orchestration.smart_selection_rules",
    "new_automation_types": "Extend cli.json and implement in cli.py",
    "new_llm_backends": "Implement in llm_client.py following existing patterns"
  }
}
