# üîß JSON SYSTEM OPTIMIZATION RESEARCH

**–î–∞—Ç–∞**: 29.05.2025  
**–°—Ç–∞—Ç—É—Å**: –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∞  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç**: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è  

---

## üéØ –ò–°–•–û–î–ù–ê–Ø –ü–†–û–ë–õ–ï–ú–ê–¢–ò–ö–ê

**–ö–æ–Ω—Ç–µ–∫—Å—Ç**: –ú–∞—Å—à—Ç–∞–±–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞ (GitHub Issues/Epics/Branches) —Ç—Ä–µ–±—É—é—Ç –ø–µ—Ä–µ–æ—Å–º—ã—Å–ª–µ–Ω–∏—è JSON –æ–±–≤—è–∑–∫–∏ –∏ LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏.

**–ö–ª—é—á–µ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã:**
1. GitHub Discussions –¥–ª—è –∏–¥–µ–π vs Issues
2. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è struct.json updates (—Å–µ–π—á–∞—Å –∫–∞–∂–¥–∞—è CLI –æ–ø–µ—Ä–∞—Ü–∏—è ‚Üí update)
3. –ß–∞—Å—Ç–∏—á–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ JSON —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
4. On-the-fly JSON wrapping —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–¥–∞
5. –ë–∞–ª–∞–Ω—Å –ø–æ–ª–Ω–æ—Ç—ã vs –º–∏–Ω–∏–º–∞–ª–∏–∑–º–∞ –¥–ª—è LLM
6. LLM-–∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

---

## üìã –†–ê–ë–û–ß–ò–ï –ó–ê–ü–ò–°–ö–ò - –°–ò–°–¢–ï–ú–ê –ê–ù–ê–õ–ò–ó–ê

### **–ù–ê–ü–†–ê–í–õ–ï–ù–ò–ï 1: GitHub Discussions vs Issues –¥–ª—è –∏–¥–µ–π**

**–¢–ï–ö–£–©–ï–ï –°–û–°–¢–û–Ø–ù–ò–ï:**
- –ò–¥–µ–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –∫–∞–∫ Issues
- Issues –∏–º–µ—é—Ç —á–µ—Ç–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É (acceptance criteria, labels)
- –ò–¥–µ–∏ —Å–º–µ—à–∏–≤–∞—é—Ç—Å—è —Å concrete tasks

**–í–ê–†–ò–ê–ù–¢: GitHub Discussions –¥–ª—è –∏–¥–µ–π**
```
Workflow: Ideas ‚Üí Discussions ‚Üí Issues ‚Üí Epics
‚îú‚îÄ‚îÄ Discussion: Brainstorming, exploration, questions
‚îú‚îÄ‚îÄ Refinement: Convert promising ideas to Issues  
‚îú‚îÄ‚îÄ Planning: Group Issues into Epics
‚îî‚îÄ‚îÄ Execution: Work on Issues in branches
```

**–ü–õ–Æ–°–´:**
- ‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ exploration vs execution
- ‚úÖ Community engagement (comments, voting)
- ‚úÖ Less noise –≤ issue tracker
- ‚úÖ Natural evolution: idea ‚Üí discussion ‚Üí issue

**–ú–ò–ù–£–°–´:**
- ‚ùå –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å workflow
- ‚ùå –ù—É–∂–Ω–∞ migration —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∏–¥–µ–π
- ‚ùå –†–∏—Å–∫ "–ø–æ—Ç–µ—Ä—è—Ç—å" —Ö–æ—Ä–æ—à–∏–µ –∏–¥–µ–∏ –≤ discussions

### **–ù–ê–ü–†–ê–í–õ–ï–ù–ò–ï 2: struct.json Update Optimization**

**–ü–†–û–ë–õ–ï–ú–ê:** –ö–∞–∂–¥–∞—è CLI –æ–ø–µ—Ä–∞—Ü–∏—è ‚Üí struct.json update
```python
# –¢–µ–∫—É—â–µ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ (–ø—Ä–æ–±–ª–µ–º–∞—Ç–∏—á–Ω–æ)
def any_file_operation():
    # –û–ø–µ—Ä–∞—Ü–∏—è —Å —Ñ–∞–π–ª–æ–º
    update_struct_json()  # –ö–∞–∂–¥—ã–π —Ä–∞–∑!
```

**–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –í–ê–†–ò–ê–ù–¢–´:**

**2.1 Conditional Updates**
```python
def smart_struct_update():
    if should_update_struct():
        # –¢–æ–ª—å–∫–æ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        # –ù–æ–≤—ã–µ —Ñ–∞–π–ª—ã, —É–¥–∞–ª–µ–Ω–∏–µ –º–æ–¥—É–ª–µ–π, etc.
        update_struct_json()
        
def should_update_struct():
    return (
        new_files_added() or 
        modules_deleted() or
        significant_refactoring() or
        manual_trigger()
    )
```

**2.2 Batched Updates**
```python
class StructUpdateManager:
    def __init__(self):
        self.pending_changes = []
        self.last_update = time.time()
    
    def schedule_update(self, change_type, metadata):
        self.pending_changes.append((change_type, metadata))
        
    def maybe_update(self):
        if self.should_flush():
            self.flush_updates()
    
    def should_flush(self):
        return (
            len(self.pending_changes) > 10 or
            time.time() - self.last_update > 300 or  # 5 minutes
            has_critical_change()
        )
```

**2.3 Session-based Updates**
```python
# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –≤ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–∞—Ö
session_start() ‚Üí update_struct_json()  # –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
# ... –º–Ω–æ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π ...
session_end() ‚Üí update_struct_json()    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
commit() ‚Üí update_struct_json()         # –ü–æ—Å–ª–µ –∫–æ–º–º–∏—Ç–∞
```

### **–ù–ê–ü–†–ê–í–õ–ï–ù–ò–ï 3: Partial JSON Retrieval**

**–°–£–©–ï–°–¢–í–£–Æ–©–ò–ô –§–£–ù–ö–¶–ò–û–ù–ê–õ:** –ß–∞—Å—Ç–∏—á–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ JSON —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π

**–ê–ù–ê–õ–ò–ó IMPLEMENTATION:**
```python
# –°—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ (–Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å)
def get_relevant_struct(context, scope="module"):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é —á–∞—Å—Ç—å struct.json
    context: —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª/–º–æ–¥—É–ª—å/–∑–∞–¥–∞—á–∞
    scope: —É—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏
    """
    pass

# –í–æ–∑–º–æ–∂–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
class SmartJSONRetrieval:
    def get_context_aware_struct(self, current_file, task_context):
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –º–æ–¥—É–ª–∏
        relevant_modules = self.find_related_modules(current_file)
        
        # –í–∫–ª—é—á–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        dependencies = self.get_dependencies(relevant_modules)
        
        # –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π JSON
        return self.build_minimal_struct(relevant_modules + dependencies)
```

**OPTIMIZATION OPPORTUNITIES:**
- Semantic search –ø–æ struct.json
- Caching —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- Adaptive context size based –Ω–∞ LLM capacity
- Priority-based inclusion (core modules first)

### **–ù–ê–ü–†–ê–í–õ–ï–ù–ò–ï 4: On-the-fly JSON Wrapping**

**–ö–û–ù–¶–ï–ü–¶–ò–Ø:** Real-time wrapping —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–¥–∞ –≤ JSON –¥–ª—è LLM

**–ê–†–•–ò–¢–ï–ö–¢–£–†–ù–´–ï –í–ê–†–ò–ê–ù–¢–´:**

**4.1 Contextual Code Wrapping**
```python
class CodeContextBuilder:
    def wrap_for_llm(self, target_file, operation_type):
        context = {
            "target": self.analyze_file(target_file),
            "related": self.find_related_files(target_file),
            "dependencies": self.get_import_chain(target_file),
            "usage_patterns": self.extract_usage_patterns(target_file)
        }
        return self.format_for_llm(context, operation_type)
    
    def format_for_llm(self, context, operation_type):
        if operation_type == "refactor":
            return self.refactor_context(context)
        elif operation_type == "extend":
            return self.extension_context(context)
        elif operation_type == "debug":
            return self.debug_context(context)
```

**4.2 Dynamic Context Assembly**
```python
def build_llm_context(request):
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ –ª–µ—Ç—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–∞–ø—Ä–æ—Å–∞
    """
    context_layers = []
    
    # Layer 1: Core project structure
    context_layers.append(get_core_structure())
    
    # Layer 2: Task-specific context  
    if request.task_id:
        context_layers.append(get_task_context(request.task_id))
    
    # Layer 3: File-specific context
    if request.files:
        context_layers.append(wrap_files_context(request.files))
    
    # Layer 4: Historical context
    if request.include_history:
        context_layers.append(get_usage_history(request.scope))
    
    return optimize_context_size(context_layers, request.llm_limits)
```

### **–ù–ê–ü–†–ê–í–õ–ï–ù–ò–ï 5: –ü–æ–ª–Ω–æ—Ç–∞ vs –ú–∏–Ω–∏–º–∞–ª–∏–∑–º Balance**

**–ü–†–û–ë–õ–ï–ú–ê:** –ù–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É complete context –∏ LLM token limits

**–°–¢–†–ê–¢–ï–ì–ò–ò:**

**5.1 Adaptive Context Sizing**
```python
class AdaptiveContextManager:
    def __init__(self, llm_config):
        self.max_tokens = llm_config.context_limit
        self.reserved_tokens = llm_config.response_buffer
        self.available_tokens = self.max_tokens - self.reserved_tokens
    
    def optimize_context(self, full_context):
        # Prioritized context assembly
        priority_layers = [
            ("task_description", 0.15),  # 15% of available tokens
            ("core_modules", 0.25),      # 25% 
            ("related_files", 0.30),     # 30%
            ("dependencies", 0.20),      # 20%
            ("history", 0.10)            # 10%
        ]
        
        optimized = {}
        used_tokens = 0
        
        for layer_name, ratio in priority_layers:
            layer_limit = int(self.available_tokens * ratio)
            layer_content = self.compress_layer(
                full_context[layer_name], 
                layer_limit
            )
            optimized[layer_name] = layer_content
            used_tokens += count_tokens(layer_content)
        
        return optimized, used_tokens
```

**5.2 Semantic Compression**
```python
def semantic_compress(content, target_size):
    """
    –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —Å–∂–∞—Ç–∏–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å–µ–º–∞–Ω—Ç–∏–∫–∏
    """
    # –£–¥–∞–ª–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å docstrings)
    # –°–æ–∫—Ä–∞—Ç–∏—Ç—å –∏–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö
    # –£–±—Ä–∞—Ç—å redundant imports
    # –û—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã
    pass

def expand_on_demand(compressed_context, expansion_request):
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É LLM
    """
    if "need_more_details_about" in expansion_request:
        target = extract_target(expansion_request)
        return get_detailed_context(target)
```

---

## ü§ñ LLM-ENGINEERING PERSPECTIVE

### **–ü–†–û–ë–õ–ï–ú–´ –¢–ï–ö–£–©–ï–ì–û –ü–û–î–•–û–î–ê:**

**1. Information Overload**
- struct.json –º–æ–∂–µ—Ç –±—ã—Ç—å 500KB+
- LLM —Ç—Ä–∞—Ç–∏—Ç tokens –Ω–∞ irrelevant information
- –°–Ω–∏–∂–∞–µ—Ç—Å—è –∫–∞—á–µ—Å—Ç–≤–æ focus –Ω–∞ actual task

**2. –°—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å Context**
- –û–¥–∏–Ω–∞–∫–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á
- –ù–µ—Ç –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫ LLM capabilities
- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ iterative refinement

**3. –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ Feedback Loop**
- –ù–µ –∑–Ω–∞–µ–º –∫–∞–∫–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –±—ã–ª –ø–æ–ª–µ–∑–µ–Ω
- –ù–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- LLM –Ω–µ –º–æ–∂–µ—Ç –∑–∞–ø—Ä–æ—Å–∏—Ç—å additional context

### **LLM-–ò–ù–ñ–ï–ù–ï–†–ù–´–ï –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:**

**1. Context Strategy Pattern**
```python
class ContextStrategy:
    def prepare_context(self, task, llm_config):
        pass

class RefactoringContext(ContextStrategy):
    def prepare_context(self, task, llm_config):
        return {
            "current_code": task.target_file,
            "architectural_patterns": get_project_patterns(),
            "similar_refactorings": get_refactoring_history(),
            "constraints": get_project_constraints()
        }

class NewFeatureContext(ContextStrategy):
    def prepare_context(self, task, llm_config):
        return {
            "feature_spec": task.description,
            "existing_modules": get_related_modules(),
            "integration_points": find_integration_points(),
            "test_patterns": get_testing_patterns()
        }
```

**2. Progressive Context Loading**
```python
def progressive_llm_interaction():
    # Stage 1: Minimal context –¥–ª—è understanding
    initial_response = llm.ask(minimal_context + task)
    
    # Stage 2: LLM requests specific information
    if "need_more_info" in initial_response:
        additional_context = prepare_additional_context(
            initial_response.requests
        )
        final_response = llm.ask(additional_context + task)
    
    return final_response
```

**3. Context Quality Metrics**
```python
class ContextQualityTracker:
    def track_context_usage(self, context, llm_response, human_feedback):
        # –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫–∏–µ —á–∞—Å—Ç–∏ context –±—ã–ª–∏ –ø–æ–ª–µ–∑–Ω—ã
        # Tracking unused information
        # Measuring response quality correlation
        pass
    
    def optimize_future_contexts(self):
        # –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ historical data
        # Automatic context template optimization
        pass
```

---

## üìä –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø PROPOSALS

### **IMMEDIATE OPTIMIZATIONS (Quick Wins):**

**1. Smart struct.json Updates**
```python
# –ó–∞–º–µ–Ω–∏—Ç—å update –Ω–∞ –∫–∞–∂–¥–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏
UPDATE_TRIGGERS = [
    "new_module_created",
    "module_deleted", 
    "session_start",
    "session_end",
    "commit_made",
    "manual_request"
]
```

**2. Context Size Monitoring**
```python
def monitor_context_efficiency():
    context_size = count_tokens(current_context)
    llm_usage = track_llm_token_usage()
    efficiency = llm_usage.useful_tokens / context_size
    return efficiency
```

**3. Lazy Context Loading**
```python
def get_context_on_demand(base_context, llm_requests):
    # –ù–∞—á–∏–Ω–∞—Ç—å —Å minimal context
    # –†–∞—Å—à–∏—Ä—è—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É LLM
    pass
```

### **MEDIUM-TERM IMPROVEMENTS:**

**1. GitHub Discussions Integration**
- Migrate brainstorming ideas to Discussions
- Structured workflow: Discussions ‚Üí Issues ‚Üí Epics
- API integration –¥–ª—è tracking discussion‚Üíissue conversion

**2. Semantic Context Search**
```python
def find_relevant_context(query, max_tokens):
    # Semantic search –ø–æ struct.json
    # Vector embeddings –¥–ª—è code understanding
    # Relevance scoring
    pass
```

**3. LLM Context Feedback Loop**
```python
def interactive_context_building():
    # LLM –º–æ–∂–µ—Ç –∑–∞–ø—Ä–æ—Å–∏—Ç—å additional information
    # Human –º–æ–∂–µ—Ç override context decisions
    # System learns from successful interactions
    pass
```

### **LONG-TERM ARCHITECTURAL CHANGES:**

**1. Microcontext Architecture**
```python
# –†–∞–∑–±–∏—Ç—å struct.json –Ω–∞ –º–∏–∫—Ä–æ-–∫–æ–Ω—Ç–µ–∫—Å—Ç—ã
contexts = {
    "core_modules": "core_struct.json",
    "utilities": "utils_struct.json", 
    "integrations": "integrations_struct.json",
    "tests": "tests_struct.json"
}
```

**2. Real-time Context Assembly**
- Dynamic context building based –Ω–∞ current task
- Integration —Å IDE –¥–ª—è real-time code understanding
- Streaming context updates to LLM

**3. Multi-modal Context**
- Code structure + natural language descriptions
- Visual dependency graphs
- Interactive context exploration

---

## üîç –ê–ù–ê–õ–ò–ó –°–£–©–ï–°–¢–í–£–Æ–©–ï–ì–û –§–£–ù–ö–¶–ò–û–ù–ê–õ–ê

### **–ß–¢–û –£–ñ–ï –†–ï–ê–õ–ò–ó–û–í–ê–ù–û (–Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å):**

**1. Partial JSON Retrieval**
- –ì–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∫–æ–¥?
- –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç filtering?
- –ö–∞–∫–∏–µ –µ—Å—Ç—å bottlenecks?

**2. On-the-fly JSON Wrapping**
- –ï—Å—Ç—å –ª–∏ —É–∂–µ implementation?
- –ö–∞–∫–∏–µ –µ—Å—Ç—å optimization opportunities?
- Integration —Å —Ç–µ–∫—É—â–∏–º workflow?

**3. LLM Context Management**
- –¢–µ–∫—É—â–∏–µ strategies
- Performance metrics
- User satisfaction

### **REVERSE ENGINEERING PLAN:**

```bash
# –ù–∞–π—Ç–∏ existing functionality
grep -r "partial.*json" src/
grep -r "relevant.*struct" src/
grep -r "context.*llm" src/

# –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å performance
python -m profile existing_context_builder.py
```

---

**üìå –°–¢–ê–¢–£–°: –ì–æ—Ç–æ–≤ –∫ –¥–µ—Ç–∞–ª—å–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É existing code –∏ —Å–æ–∑–¥–∞–Ω–∏–µ optimization roadmap** 